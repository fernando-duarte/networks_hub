%%%2multibyte Version: 5.50.0.2953 CodePage: 1252
%%\input{tcilatex}

%% To consider adding: Macro uses fire sells more and more for inyermediary frictions, but should not forget this default 
The financial crisis of 2007-2008 renewed economic interest in the network structure of the financial system and the interactions between the financial sector and the real economy. Since then, academic research on financial networks has grown substantially, vastly improving our understanding of how interconnectedness among economic agents arises, evolves and ultimately affects the economy. Because detailed empirical data on financial networks is almost always insufficient to perform consequential analyses, the literature has predominantly focused on theoretical aspects, while acknowledging the limitations that a lack of empirical results imposes on our understanding. Although there is a decent understanding of certain empirical aspects of the structure of the financial network, like its core-periphery topology or its increasing complexity, there is not as much knowledge about welfare-relevant attributes of networks, such as the size of network spillovers, the degree of propagation and amplification of shocks through network effects, or how network vulnerability varies as a function of the shock size. In general, the literature approaches welfare-relevant questions by constructing top-down measures of systemic risk or interconnectedness that rely on more-readily available data (such as stock market returns) instead of actual network-specific data. To tie non-network specific data to welfare-relevant network variables requires a model, or at least some auxiliary assumptions that are difficult to test without network-specific data.

In this paper, using node-specific data, we empirically estimate a measure of expected network default spillovers for the US financial system for the period 2002-2016. Although default spillovers are only one dimension of potential network effects, they have been repeatedly cited as a major factor during the financial crisis, motivating existing regulation and studies by the theoretical network literature. We build our measure of spillovers by using the general and elegant framework of Eisenberg and Noe. The nodes of the network are US financial institutions, including bank holding companies, broker-dealers, and insurance companies. The connections between nodes are defined by the bilateral payment obligations between them. We refer to these claims as \textit{inside} assets or liabilities. In addition, each node has assets from and liabilities to the \textit{outside} sector, composed of non-financial firms, households, governments, and financial firms outside the US. Our primary measure of network vulnerability will quantify expected network spillovers in the face of an exogenous shock to these outside assets. The primary method for contagion in the model is a ``default cascade'', whereby a shock to outside assets can cause some institutions to default on their in-network counterparties, which could in turn cause those counterparties to default on their own inside obligations, and so on. This “domino” effect can propagate through the financial system, creating network spillovers.

Empirically estimating the expected value of these spillovers requires knowledge of the bilateral claims between each pair of nodes. Such granularity of data is not publicly available\footnote{In the network simulaion literature, a common method to compute exact payments in the response to a shock is to assume a ``maximum entropy'' form to inside obligations. In the presence of any uncertainty about the structure of bilateral claims, this essentially spreads a node's inside obligations as evenly as possible across potential counterparties.}. However, \citet{glasserman2015likely} show that, for a large family of exogenous shock distributions, a meaningful upper bound on the expected value of default spillovers can be constructed with knowledge of node-specific information only (i.e. without a precise breakdown of the nodes' counterparties or the magnitudes of obligations to them). In particular, the bound is based on each node's probability of default, its total outside assets and its ratio of inside liabilities to total liabilities. The empirical measure of spillovers that we estimate is this upper bound on the expected value of default spillovers proposed by \citet{glasserman2015likely}. Thus, at the cost of estimating an upper bound on spillovers instead of their actual values, the data requirements are greatly reduced. For a significant portion of all US financial institutions (constituting 21\% of total assets in the network), we use detailed balance sheet data from the FR-Y9C reporting form to construct all relevant variables. When detailed line-item balance sheets are unavailable (as is the case for most insurance companies and broker-dealers in our sample), we combine remaining firms into more-aggregated, sector-level nodes, and use the Federal Reserve's Financial Accounts of the United States (formerly known as Flow of Funds) to estimate outside assets at the sector level\footnote{Including these additional assets brings the quantity of assets in the domestic financial sector accounted for in our sample up to 35\%}. We obtain the last ingredient, firm-specific probabilities of default, from Moody’s Analytics' (formerly KMV) Expected Default Frequency series.

We find that between 2002 and 2007 the upper bound on default spillovers is rather small, which means that the financial network is robust to contagion arising from counterparty risk. However, between 2008 and 2012, the upper bound on spillovers is meaningfully above zero. Our results suggest that the financial network is most fragile in the first quarter of 2009, when we estimate that network default spillovers can amplify initial losses by up to $25$ percent. After 2012, the upper bound on default spillovers starts to decline and reverts to pre-crisis levels by 2015. In 2016 and 2017, the last two years of our sample, our measure of spillovers starts to increase again --- slowly but consistently.

One way to understand our results is to decompose the upper bound on default spillovers into two factors: A weighted average default probability for the sample and a \textit{connectivity multiplier} that captures how the initial losses in outside assets could be transmitted and amplified by a default cascade. We find that both factors are important in explaining the overall dynamics of spillovers. Between 2002 and 2007, default likelihoods were negligible and the connectivity multiplier declined by around 10 percent. In 2008, default probabilities spiked, but financial connectivity declined sharply as financial institutions reduced exposures among each other amidst stressed financial and economic conditions. Even though our estimates for expected spillovers in 2008 increased, the reduction in financial connectivity was an important mitigant. In 2009, both default likelihoods and financial connectivity increased, leading to a large jump in our spillover estimates.

Another way to analyze our results is by constructing a node-specific ``contagion index", which quantifies the ability of a node to transmit and amplify losses. We find that JP Morgan Chase, Bank of America, Citigroup and Wells Fargo have the largest contagion indices. Similarly to the network-wide measure, we can decompose the contagion index into two sub-components, the node-specific financial connectivity and the size of each node's outside assets relative to its equity capital. While the contagion index of JP Morgan Chase, Bank of America and Citigroup are generally driven by their large financial connectivity, the contagion index of Wells Fargo is mainly driven by its outside assets being large relative to equity capital. 

To the best of our knowledge, our paper is the first to empirically assess network spillovers across many years and for a wide cross-section of US financial institutions. Having a panel has several advantages. First, it allows us to better identify the drivers of spillovers. Second, it places tighter restrictions on theoretical models that seek to model default spillovers. Third, it provides information that is potentially useful to policymakers and regulators, such as the quantitative contribution of spillovers to systemic risk.

\textbf{Related Literature.} Some of the first studies into financial network topologies and the relative vulnerabilities of different networks were the seminal theoretical models of \citet{allen2000financial} and \citet{freixas2000systemic}, both of which model liquidity crises at depository institutions. In both, the central takeaways were that different configurations of networks (all of which, in their studies, were purely hypothetical) could either alleviate the risk of contagion or exacerbate it. Since then, many papers have used simulations to estimate the severity of losses in interconnected banking networks in the face of a variety of shocks. Examples include \citet{upper2004estimating} for the German banking system, \citet{elsinger2006riska} and \citet{elsinger2006riskb} for the Austrian Banking System, and \citet{vanLelyveld2006} for Dutch Banks\footnote{See \citet{upper2011survey} for a useful survey of simulation-based contagion risk estimations}. \citet{drehmann2013} develop and test bank-specific, simulation-based measures of systemic risk for 20 large financial institutions. 

Another strand of the literature focuses on characterizing the topology of financial networks, using either degree distributions as in \citet{boss2004empirical} or searches for a core-periphery structure in banking systems as in \citet{craigvonpeter2014}\footnote{See \citet{glassermanSurvey2016} for a general survey of the networks literature, including a dedicated discussion of networks specific-measures such as degree distributions, core-periphery structures, and the related concept of node depth.}. For these studies, the lack of usable data on bilateral claims in the financial system has necesitated assumptions to fill gaps in balance sheet data or, in the case of \citet{vanLelyveld2006}, incomplete bilateral claims data restricted to a subset of the balance sheet of a subset of all financial institutions. Studies quantifying losses through simulation require explicit and potentially-stringent assumptions about shock distributions.

A separate subset of papers sheds the analysis of counterfactual shocks entirely, in favor of strictly empirical analysis. \citet{gropp2009}, for instance, find evidence of comovement in market-based estimates of  probability of default for large European financial institutions which, they argue, are reasonably attributable to contagion effects. Similarly, \citet{hawkesby2007} analyze comovements between asset prices of several large multinational financial institutions. As \citet{hawkesby2007} note, while they may give interesting insight into market perceptions of interconnectedness or potential co-exposure to common factors, these studies do not attempt to `capture the degree of contagion that may occur during periods of financial stress'. Another related strategy has been to use market data, such as stock returns, to construct ``top down" measures of systemic risk that indirectly relate to the actual network structure, as in \citet{adrian2016covar}, \citet{acharya2017measuring}, or \citet{brownlees2016srisk}.

The framework of \citet{eisenberg2001systemic} is a common thread through much of the recent financial networks literature. Their model presents an intuitive and general system for intra-network defaults and payment shortfalls in the presence of fully general shocks to assets outside the network, bound by simple rules such as limited liability and debt seniority\footnote{Particularly, many simulation-based studies of contagion risk rely on the \citet{eisenberg2001systemic} algorithm to find a sequence of network `clearing' payments after a shock to assets outside the network.}. Building on their findings, \citet{glasserman2015likely} derive useful bounds on contagion losses without additional assumptions regarding bilateral claims, and for a broad family of shock distributions. A substantial portion of our paper can be viewed as an empirical estimation of these bounds. 

After deriving their theoretical upper bounds, \citet{glasserman2015likely} employ data from the European Banking Authority's (EBA) 2011 stress test and simplifying assumptions to argue that default spillovers, on their own, are likely to be small unless further frictions, such as bankrupcy costs or bank runs, are also present. Much of the literature supports this view (e.g. \citet{upper2004estimating}). We find that even for pure default spillovers that do not interact with any other frictions, we cannot dismiss the possibility of sizable spillover effects (for the first quarter of 2009, we find that default spillovers can amplify initial exogenous losses by up to 25\%). The main reason why other studies find negligible spillovers while we do not is that the default probabilities for the financial institutions we analyze are substantially larger than the probabilities of default of the institutions used in other studies (which are almost always European banks). In addition, the share of in-network liabilities to total liabilities (a measure of network connectivity) that we empirically estimate are also somewhat larger than those in \citet{glasserman2015likely} and the rest of the literature.
