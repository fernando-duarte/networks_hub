{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6346e4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Pkg;\n",
    "\n",
    "# basic packages\n",
    "using LinearAlgebra, Random, Distributions, Test, Markdown\n",
    "\n",
    "# packages for nice output\n",
    "Pkg.add(\"Latexify\"); Pkg.add(\"LaTeXStrings\"); Pkg.add(\"Formatting\");Pkg.add(\"PrettyTables\")\n",
    "using Latexify, LaTeXStrings, Formatting, PrettyTables\n",
    "\n",
    "# packages to plot networks\n",
    "Pkg.add(\"LightGraphs\"); Pkg.add(\"SimpleWeightedGraphs\"); Pkg.add(\"Gadfly\"); Pkg.add(\"GraphRecipes\")\n",
    "using Plots, LightGraphs, SimpleWeightedGraphs, GraphRecipes\n",
    "\n",
    "# packages for general plots\n",
    "Pkg.add(\"Gadfly\"), Pkg.add(\"Cairo\")\n",
    "using Gadfly, Cairo\n",
    "\n",
    "# packages for optimization\n",
    "using NLsolve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556172c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enable equation numbering in MathJax\n",
    "\n",
    "# macro to use javascript inside notebook\n",
    "macro javascript_str(s) display(\"text/javascript\", s); end;\n",
    "\n",
    "#=\n",
    "javascript\"\"\"\n",
    "MathJax.Hub.Config({\n",
    "    TeX: { equationNumbers: { autoNumber: \"AMS\" } }\n",
    "});\n",
    "\"\"\"\n",
    "=#\n",
    "\n",
    "#=\n",
    "javascript\"\"\"\n",
    "MathJax.Hub.Register.StartupHook(\"TeX AMSmath Ready\", function () {\n",
    "  var AMS = MathJax.Extension['TeX/AMSmath'];\n",
    "  MathJax.InputJax.TeX.postfilterHooks.Add(function (data) {\n",
    "    var jax = data.script.MathJax;\n",
    "    jax.startNumber = AMS.startNumber;\n",
    "    jax.eqLabels = AMS.eqlabels;\n",
    "    jax.eqIDs = AMS.eqIDs;\n",
    "  });\n",
    "  MathJax.InputJax.TeX.prefilterHooks.Add(function (data) {\n",
    "    var jax = data.script.MathJax;\n",
    "    if (jax.startNumber != undefined) {\n",
    "      AMS.startNumber = jax.startNumber;\n",
    "      Object.keys(jax.eqLabels).forEach(function (x) {delete AMS.labels[x]});\n",
    "      Object.keys(jax.eqIDs).forEach(function (x) {delete AMS.IDs[x]});\n",
    "    }\n",
    "  }, 1);\n",
    "});\n",
    "\n",
    "\"\"\"\n",
    "=#\n",
    "\n",
    "#=\n",
    "javascript\"\"\"\n",
    "MathJax.Hub.Queue(\n",
    "  [\"resetEquationNumbers\", MathJax.InputJax.TeX],\n",
    "  [\"PreProcess\", MathJax.Hub],\n",
    "  [\"Reprocess\", MathJax.Hub]\n",
    ");\n",
    "\"\"\"\n",
    "=#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5eb057",
   "metadata": {},
   "source": [
    "Overview\n",
    "--------\n",
    "\n",
    "The network model we use is exactly as in [Glasserman and Young (2015)](https://www.sciencedirect.com/science/article/pii/S0378426614000600). The nodes of the network\n",
    "are all US domestic financial institutions. The connections between\n",
    "nodes are defined by institutions borrowing from and lending to one\n",
    "another. There is a link from node $i$ to node $j$ if $i$ has any\n",
    "net payment obligations towards node $j$. In addition to lending to one\n",
    "another, nodes can borrow and lend to the rest of the domestic and\n",
    "global economy. These assets and liabilities are termed as *outside* the\n",
    "financial system. In our application, the *outside* sector is comprised\n",
    "of domestic and foreign non-financial institutions, governments, and\n",
    "households, as well as foreign financial institutions.\n",
    "\n",
    "<a href=\"#Fig1\">Figure 1</a> shows an example of a simple network, taken from [Glasserman and Young (2015)](https://www.sciencedirect.com/science/article/pii/S0378426614000600). The four arrows\n",
    "originating in the central node and pointing to the four peripheral\n",
    "nodes show that the central node owes $10$ to each of the peripheral\n",
    "nodes. The four peripheral nodes have no borrowing or lending among\n",
    "themselves. For this network, we say that the central node has *inside\n",
    "liabilities* of $40$, while each of the peripheral nodes has *inside\n",
    "assets* of $10$. In practice, we find that inside assets and liabilities\n",
    "for US financial institutions are primarily composed of deposits, loans\n",
    "and securities lending transactions.\n",
    "\n",
    "<figure>\n",
    "    <img src='../../paper/fig1_networkExample.png' alt='Example of a network' id=\"Fig1\" />\n",
    "    <figcaption>Figure 1: A simple network</figcaption>\n",
    "</figure>\n",
    "\n",
    "In addition to its claims inside the network, the central node has lent\n",
    "$150$ and has borrowed $100$ from the outside sector, depicted by the\n",
    "doted lines with arrows going into and out of the central node. We\n",
    "refer to positive claims with respect to the outside sector as *outside\n",
    "assets* and to negative claims as *outside liabilities*. Outside assets\n",
    "typically consist of securities, loans to firms and households\n",
    "(including mortgages), and public debt. Outside liabilities mostly\n",
    "involve deposits and lines of credit.\n",
    "\n",
    "The difference between all assets and all liabilities gives each node’s\n",
    "net worth. The central node has a net worth of $10$, shown inside the\n",
    "circle that represents the node. Each of the peripheral nodes has\n",
    "outside assets of $50$, outside liabilities of $55$ and an inside asset\n",
    "of $10$ with respect to the central node, for a net worth of $5$.\n",
    "\n",
    "We will use the following notation for the objects of the network:\n",
    "\n",
    "$$\\begin{aligned}\n",
    "\\bar{p}_{i} &:\\text{total liabilities for node }i, \\\\\n",
    "f_{i} &:\\text{inside liabilities for node }i,\\\\\n",
    "b_{i} &:\\text{outside liabilities for node }i, \\\\\n",
    "a_{i} &:\\text{total assets for node }i, \\\\\n",
    "d_{i} &:\\text{inside assets for node }i, \\\\\n",
    "c_{i} &:\\text{outside assets for node }i, \\\\\n",
    "w_{i} &:\\text{net worth for node }i.\n",
    "\\end{aligned}$$\n",
    "\n",
    "All of the above variables are node-specific, that is, are characteristics of node $i$ when the node is considered in isolation, requiring knowledge of neither how $i$ is connected to other nodes nor of characteristics of other nodes.\n",
    "\n",
    "We denote the number of nodes of the network by $N$. To keep track of the connections among nodes, we define the $N \\times N$ *relative liabilities matrix* $A$ by\n",
    "\n",
    "$$a_{ij}=\\left\\{ \n",
    "\\begin{array}{ccc}\n",
    "\\bar{p}_{ij}/\\bar{p}_{i} & , & \\text{if }\\bar{p}_{i}>0 \\\\ \n",
    "0 & , & \\text{if }\\bar{p}_{i}=0\n",
    "\\end{array}%\n",
    "\\right.$$\n",
    "\n",
    "where $\\bar{p}_{ij}$ represents the net payments due from $i$ to $j$. Because $a_{ij}$ represents *net* payments, we have that\n",
    "\n",
    "$$\\begin{aligned}\n",
    "a_{ii} &=0\\text{,} &\\text{ for }i=1,..,N \\\\\n",
    "a_{ij}a_{ji} &=0 \\text{,} &\\text{ for }i=1,..,N\\text{ and }j<i.\n",
    "\\end{aligned}$$\n",
    "\n",
    "In addition, because payments to $i$ from other nodes $j$ add up to inside assets $d$, we have \n",
    "\n",
    "$$\\begin{aligned}\n",
    "\\sum_{j=1}^{n}a_{ji}\\bar{p}_{j} &=d_{j}\\text{,} &\\text{ for }i=1,..,N.\n",
    "\\end{aligned}$$\n",
    "\n",
    "And because payments from $i$ to other nodes add up to inside liabilities $f$, we have\n",
    "\n",
    "$$\\begin{aligned}\n",
    "\\bar{p}_{i}\\sum_{j=1}^{n}a_{ij} &=f_{i}\\text{,} &\\text{ for }i=1,..,N. \\\\\n",
    "\\end{aligned}$$\n",
    "\n",
    "Last, by definition, the variables satisfy the following bounds\n",
    "\n",
    "$$\\begin{aligned}\n",
    "0 &\\leq c_{i} \\leq assets_{i} & \\text{,} &\\text{ for }i=1,..,N \\\\\n",
    "0 &\\leq b_{i} \\leq \\bar{p}_{i} & \\text{,} &\\text{ for }i=1,..,N \\\\\n",
    "0 &\\leq a_{ij} \\leq 1 & \\text{,} & \\text{ for }i,j=1,..,N.\n",
    "\\end{aligned}$$\n",
    "\n",
    "Now we create and plot the network of <a href=\"#Fig1\">Figure 1</a> using Julia. First, we define the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f93dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_bar = (55.0, 55.0, 140.0, 55.0, 55.0); # total liabilities\n",
    "b = (55.0, 55.0, 100.0, 55.0, 55); # outside liabilities\n",
    "c = (50.0, 50.0, 150.0, 50.0, 50.0); # outside assets\n",
    "w = (5.0, 5.0, 10.0, 5.0, 5.0); # net worth\n",
    "A = [0 0 0 0 0; 0 0 0 0 0; 10.0/p_bar[3] 10.0/p_bar[3] 0 10.0/p_bar[3] 10.0/p_bar[3]; 0 0 0 0 0; 0 0 0 0 0]; # matrix of relative liabilities\n",
    "a = w .+ p_bar; # total assets\n",
    "d =  a .- c; # inside assets\n",
    "f = p_bar .- b; # inside liabilities\n",
    "N = length(c); # number of nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe9a2fd",
   "metadata": {},
   "source": [
    "Now we plot the financial network (without outside assets and liabilities)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752b5e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "Aplot = deepcopy(A);\n",
    "Aplot[Aplot.<1e-3] .= 0; # do not show very small edges\n",
    "\n",
    "graphplot(LightGraphs.DiGraph(Aplot),\n",
    "          nodeshape = :circle,\n",
    "          markersize = 0.1,\n",
    "          node_weights = w,\n",
    "          markercolor = :white, #range(colorant\"yellow\", stop=colorant\"red\", length=N+1),\n",
    "          names = w,\n",
    "          fontsize = 8,\n",
    "          linecolor = :darkgrey,\n",
    "          edgewidth = (s,d,w)->15*Aplot[s,d], # width proportional to relative liabilities\n",
    "          arrow = true,\n",
    "          method = :sfdp,\n",
    "          curves = false,\n",
    "          edgelabel = p_bar.*A,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be9a4fc",
   "metadata": {},
   "source": [
    "To plot the network with outside assets and liabilities that looks like <a href=\"#Fig1\">Figure 1</a>, we create a relative liabilities matrix that includes extra nodes for outside assets and liabilities. For each node inside the network, we define two extra nodes, one for outside assets and another for outside liabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6989f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Aall = vcat(hcat(p_bar.*A,Diagonal([c...]),zeros(N,N)),hcat(vcat(zeros(N,N),Diagonal([b...])),zeros(2N,2N))); # relative liabilities matrix\n",
    "Nall = size(Aall,1); # number of nodes\n",
    "\n",
    "# plot it\n",
    "graphplot(LightGraphs.DiGraph(Aall),\n",
    "          nodeshape= :circle,\n",
    "          markersize = 0.2,\n",
    "          node_weights =  [hcat([w...],[b...],[c...]).^(1/30)...],\n",
    "          markercolor = :white, #range(colorant\"yellow\", stop=colorant\"red\", length=N+1),\n",
    "          names =  trunc.(Int,hcat(w...,b...,c...)),\n",
    "          fontsize = 8,\n",
    "          edgecolor = hcat(:red,:red,:black,:black,:black,:black,:red,:red,:red,:red,:red,:red,:red,:red),\n",
    "          linestyle = hcat(:dashdot,:dashdot,:solid,:solid,:solid,:solid,:dashdot,:dashdot,:dashdot,:dashdot,:dashdot,:dashdot,:dashdot,:dashdot),\n",
    "          edgewidth = (s,d,w)->0.02*Aall[s,d],\n",
    "          arrow = true,\n",
    "          method = :stress,\n",
    "          curves = false,\n",
    "          edgelabel = trunc.(Int,Aall),\n",
    "          axis_buffer = 0.25,\n",
    "          edgelabel_offset = 0,\n",
    "          shorten = 0,\n",
    "          edge_label_box = true,\n",
    "          layout_kw = Dict(:iterations => 10000),\n",
    "          size = (1000,1000),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48095201",
   "metadata": {},
   "source": [
    "We can also try different layouts by changing the keyowrd `method`; we will probably have to try different layouts when we plot bigger networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146e74a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "graphplot(LightGraphs.DiGraph(Aplot),\n",
    "          nodeshape = :circle,\n",
    "          markersize = 0.1,\n",
    "          node_weights = w,\n",
    "          markercolor = :white, #range(colorant\"yellow\", stop=colorant\"red\", length=N+1),\n",
    "          names = w,\n",
    "          fontsize = 8,\n",
    "          linecolor = :darkgrey,\n",
    "          edgewidth = (s,d,w)->15*Aplot[s,d], # width proportional to relative liabilities\n",
    "          arrow = true,\n",
    "          method = :circular,\n",
    "          curves = false,\n",
    "          edgelabel = p_bar.*A, \n",
    "    # attributes here: https://docs.juliaplots.org/latest/generated/graph_attributes/\n",
    "    # method `:spectral`, `:sfdp`, `:circular`, `:shell`, `:stress`, `:spring`, `:tree`, `:buchheim`, `:arcdiagram` or `:chorddiagram`.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a972ed0a",
   "metadata": {},
   "source": [
    "Shocks and Propagation\n",
    "----------------------\n",
    "\n",
    "The shocks we consider are exogenous reductions in the value of outside\n",
    "assets. Therefore, all initial losses always originate outside the\n",
    "network. One example of such a shock is an increase in defaults for\n",
    "residential mortgages held by financial institutions.\n",
    "\n",
    "For sufficiently high initial losses in outside assets, some nodes in\n",
    "the network will be unable to pay their creditors in full. When this\n",
    "happens, all debts for the defaulting node (including those outside the\n",
    "network) are written down pro rata and creditors receive only a fraction\n",
    "of their promised payments. Note that under a pro rata allocation, a\n",
    "node defaults on either all of its creditors or none of them. When\n",
    "creditors for some node are not paid in full, they may themselves be\n",
    "unable to pay their own creditors, and so on. Initial losses thus get\n",
    "transmitted inside the network through this “domino” effect. We do not\n",
    "include in our analysis any liquidity or equity injections, and only net\n",
    "claims between two nodes are assumed to be of relevance (as opposed to\n",
    "gross positions). In addition, nodes do not renegotiate claims, even if\n",
    "it may be mutually beneficial to do so.\n",
    "\n",
    "As a numerical example, consider what happens when the outside assets of\n",
    "the central node in <a href=\"#Fig1\">Figure 1</a> receive a shock of size $80$. \n",
    "Outside assets for the central node\n",
    "decrease from $150$ to $70$. Total liabilities are initially $140$.\n",
    "After the shock, under a pro rata allocation, only $50$ percent of each\n",
    "liability is repaid as the central node only has $70$ remaining in\n",
    "assets. Each of the peripheral nodes receives $5$ from the central node,\n",
    "just enough to balance their assets and liabilities. A shock to the\n",
    "outside assets of the central node of magnitude greater than $80$ would\n",
    "reduce the value of assets for peripheral nodes below the value of their\n",
    "liabilities. In this case, the peripheral nodes would default on their\n",
    "creditors. In this case, the central node has created contagion to the\n",
    "peripheral nodes through network contagion. The peripheral nodes default\n",
    "even though none of their outside assets were affected by the initial\n",
    "shock.\n",
    "\n",
    "<a href=\"#Fig2\">Figure 2</a> shows a more complicated network in which a cycle of obligations of size $y$ runs through the peripheral nodes (the previous case we analyzed is obtained when $y=0$).\n",
    "\n",
    "<figure>\n",
    "    <img src='fig_networkExampleY.jpg' alt='Example of a more complicated network' id=\"Fig2\" />\n",
    "    <figcaption>Figure 2: A more complicated network</figcaption>\n",
    "</figure>\n",
    "\n",
    "To compute what happens after a shock $x=(x_1,x_2,...,x_N)$ to the outside \n",
    "assets of all nodes, \n",
    "it is necessary to first compute the *clearing vector*. The clearing vector\n",
    "is an $N \\times 1$ vector $p(x)$ such that\n",
    "\n",
    "$$\\begin{aligned}\n",
    "p_{i}(x) =\\min \\left[ \\bar{p}_{i},\\max \\left[ 0, \\sum_{j=1}^{n}a_{ji}p_{j}\\left( x\\right) +c_{i}-x_{i}\\right] \\right] &\\text{ for } i=1,..,N\n",
    "\\end{aligned}$$\n",
    "\n",
    "or, in matrix notation,\n",
    "$$\\begin{equation*}\n",
    "p(x) =\\min \\left[ \\bar{p},\\max \\left[ 0,A^{T}p\\left( x\\right)\n",
    "+c-x\\right] \\right] \\label{eq:sys} \\tag{1}\n",
    "\\end{equation*}$$\n",
    "\n",
    "The above constitutes a system of $N$ non-linear equations in the $N$ variables $p_i(x)$. The system always has a solution, and the solution is unique. The reason is that the matrix\n",
    "$A$ is substochastic (it has nonnegative entries with rows adding up to at most 1), and therefore has [spectral radius](https://en.wikipedia.org/wiki/Spectral_radius) less than 1. In turn, a spectral radius less than one makes the right-hand side of equation $\\eqref{eq:sys}$ a contraction mapping -- existence and uniqueness follows from the [Banach fixed-point theorem](https://en.wikipedia.org/wiki/Banach_fixed-point_theorem). \n",
    "\n",
    "We interpret the clearing vector $p(x)$ as a mark-to-market valuation of all assets following a shock to the system. The initial value of node $i$’s liabilities, $\\bar{p}_i$, is marked down to $p_i(x)$ as a consequence of the shock $x$, including through its impact on other nodes. This markdown reflects both the direct effect of the shock and the indirect effects of defaults spillovers.\n",
    "\n",
    "Now let's solve the system of equations for the clearing vector $p(x)$ for any $y$ using Julia. We will start by looking at the simpler case with $y=0$ and then consider $y>0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31d36d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the system of equations for the clearing vector p when the shock vector is x\n",
    "function clearing_vec!(F, p, x)\n",
    "    # when the system is solved, F is zero\n",
    "    F .= p.-min.(p_bar,max.(A'*p .+c .- x,0))\n",
    "end\n",
    "\n",
    "# define the new network with cycle of liabilities y from Figure 2\n",
    "\n",
    "# b, c and w are the same for any y (and the same as before)\n",
    "b = (55.0, 55.0, 100.0, 55.0, 55); # outside liabilities\n",
    "c = (50.0, 50.0, 150.0, 50.0, 50.0); # outside assets\n",
    "w = (5.0, 5.0, 10.0, 5.0, 5.0); # net worth\n",
    "N = length(c); # number of nodes\n",
    "\n",
    "# first consider y=0\n",
    "y = 0;\n",
    "p_bar = (55.0+y, 55.0+y, 140.0, 55.0+y, 55.0+y); # total liabilities\n",
    "A = [0 y/p_bar[1] 0 0 0; 0 0 0 y/p_bar[1] 0; 10.0/p_bar[3] 10.0/p_bar[3] 0 10.0/p_bar[3] 10.0/p_bar[3]; 0 0 0 0 y/p_bar[1]; y/p_bar[1] 0 0 0 0]; # matrix of relative liabilities\n",
    "a = w .+ p_bar; # total assets\n",
    "d = a .- c;# inside assets \n",
    "f = p_bar .- b;# inside liabilities\n",
    "\n",
    "# shock to the central node of size 80\n",
    "x = [0.0, 0.0, 80.0, 0.0, 0.0]\n",
    "sol = nlsolve((F, p)->clearing_vec!(F, p, x),[p_bar...], autodiff = :forward) \n",
    "p = sol.zero; # the solution to the system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d993b347",
   "metadata": {},
   "source": [
    "Before we move on, we do a unit test to make sure that `nlsolve` converges:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59290c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@test converged(sol)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf633e2",
   "metadata": {},
   "source": [
    "Now we can compute all the new network quantities after the shock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0398d77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# network after the shock\n",
    "# once we know p and x, we can compute all network quantities\n",
    "\n",
    "p_bar_new = p # value of total liabilities after the shock\n",
    "f_new = sum(A,dims=2).*p_bar_new # value of inside liabilities after the shock\n",
    "b_new = p_bar_new .- f_new # value of outside liabilities after the shock\n",
    "\n",
    "d_new = A'*p_bar_new #  value of inside asset safter the shock\n",
    "c_new = c.-x # value of outside assets after the shock\n",
    "a_new = d_new .+ c_new  # value of total assets after the shock\n",
    "\n",
    "w_new = a_new .- p_bar_new; # value of equity after the shock"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff77f1d6",
   "metadata": {},
   "source": [
    "Let's interpret the results. \n",
    "\n",
    "But before that, a brief detour. Jupyterlab has three types of cell: raw, markdown, and code. I have not figured out how to reference a variable from a code cell (like `p` in the previous cell) so I can display its value while in a markdown cell. In Jupyter notebooks with IPython, one can do `{{p}}` to show the value of the variable `p`. But I have not found how to do this with Jupyterlab and IJulia. \n",
    "\n",
    "So for the next bit, instead of using a markdown cell, I will use a code cell with Julia markdown. As a side benefit, it will show some nice ways to use Julia markdown. Julia markdown is useful when creating documentation for packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f0baa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## the next few lines format strings for Julia markdown\n",
    "\n",
    "# convert some variables into nice latex equations to use inside Julia markdown\n",
    "p_latex = latexify(string(\"p(x) = \", format.(p',precision=0)), env=:eq); # converts p to nice latex equation display using latexify, using format to choose number of decimals shown\n",
    "\n",
    "# create a multi-line formula using align\n",
    "p_bar_vec = [p_bar... ]; # convert tuple to vector to get square brackets (rather than parentheses) when converted to latex\n",
    "p_loss = p_bar_vec .- p; # total losses = shock plus mark to market losses in liabilities\n",
    "\n",
    "# round to integer to display without the decimals\n",
    "p_str =  round.(Int64,p)\n",
    "p_bar_str =  round.(Int64,p_bar_vec)\n",
    "p_loss_str = round.(Int64,p_loss)\n",
    "x_str = round.(Int64,x)\n",
    "w_str = latexify(string(\"w = \", format.([w...]',precision=0)), env=:eq);\n",
    "w_new_str = latexify(string(\"w = \", format.(w_new',precision=0)), env=:eq); \n",
    "\n",
    "# create each line of align environment\n",
    "diff_latex_line1 = L\" \\bar{p}-p(x) =  %$(p_bar_str) - %$(p_str)\" # L\"...\" defines a LaTeXString object, inside of which interpolation needs %$ instead of usual $\n",
    "diff_latex_line2 = L\" = %$(p_loss_str) \"\n",
    "\n",
    "# create align environment\n",
    "diff_latex=latexify([diff_latex_line1,diff_latex_line2], env=:align) \n",
    "diff_latex=replace(diff_latex,\"\\$\"=>\"\") # remove dollar sign from each line\n",
    "\n",
    "## write nice output using Julia markdown\n",
    "md\"\n",
    "The solution is contained in `p`, which in this case is $p_latex\n",
    "\n",
    "Comparing $\\bar{p}$ to $p(x)$, we get $diff_latex\n",
    "\n",
    "which is the decline in value of total liabilities for each node. We see that only the \n",
    "central node had to mark down its liabilities.\n",
    "\n",
    "On the other hand, they all experienced equity losses with initial (pre-shock) equity \n",
    "equal to $w_str and final (post-shock) equity equal to $w_new_str\n",
    "\n",
    "So fact, they all lost all of their equity.\n",
    "\n",
    "Now let's look at how things change when we have the cycle of liabilities\n",
    "for the peripheral nodes, that is, when $y>0$. \n",
    "\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550b6a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y>=0 and any shock vector x\n",
    "\n",
    "# b, c and w are the same for any y (and the same as before)\n",
    "b = (55.0, 55.0, 100.0, 55.0, 55); # outside liabilities\n",
    "c = (50.0, 50.0, 150.0, 50.0, 50.0); # outside assets\n",
    "w = (5.0, 5.0, 10.0, 5.0, 5.0); # net worth\n",
    "N = length(c); # number of nodes\n",
    "\n",
    "# compute clearing vector for cycle y and shock x\n",
    "function clearing_vec_yx(y,x)\n",
    "    p_bar = [55.0+y, 55.0+y, 140.0, 55.0+y, 55.0+y]; # total liabilities\n",
    "    A = [0 y/p_bar[1] 0 0 0; 0 0 0 y/p_bar[1] 0; 10.0/p_bar[3] 10.0/p_bar[3] 0 10.0/p_bar[3] 10.0/p_bar[3]; 0 0 0 0 y/p_bar[1]; y/p_bar[1] 0 0 0 0]; # matrix of relative liabilities\n",
    "\n",
    "    # need to re-define clearing_vec! because p_bar and A have been redefined locally inside clearing_vec_yx, while the original clearing_vec! uses the global values\n",
    "    function clearing_vec2!(F, p, x)\n",
    "        F .= p.-min.(p_bar,max.(A'*p .+c .- x,0))\n",
    "    end\n",
    "    \n",
    "    sol = nlsolve((F, p)->clearing_vec2!(F, p, x),p_bar, autodiff = :forward)\n",
    "    @test converged(sol)\n",
    "    p = sol.zero\n",
    "    return (p,p_bar)\n",
    "end\n",
    "\n",
    "# shock to the central node of size 80 with various values for y\n",
    "x = [0.0, 0.0, 80.0, 0.0, 0.0]\n",
    "y_grid = 0:100:1000\n",
    "    \n",
    "# initialize variables\n",
    "p_grid = fill([], length(y_grid),1);p_bar_grid = fill([], length(y_grid),1)\n",
    "i=1\n",
    "\n",
    "# compute the clearing vector for each y\n",
    "for y in y_grid \n",
    "    p_grid[i],p_bar_grid[i] = vcat(clearing_vec_yx(y,x))[1]\n",
    "    i=i+1\n",
    "end\n",
    "\n",
    "## show results\n",
    "headers = permutedims([\"y\", [string(\"clearing vec node \",i) for i=1:N]..., [string(\"liab markdown node \",i) for i=1:N]...]); # permutedims is like transpose but, unlike transpose (or adjoint), it works on an array of strings\n",
    "numbers = [collect(y_grid) hcat(p_grid...)' hcat(p_bar_grid...)'.-hcat(p_grid...)'];\n",
    "\n",
    "# using package Latexify\n",
    "table = vcat(headers,numbers)\n",
    "latexify(table,env=:mdtable, fmt = \"%.0f\", latex=false) |> display # show in screen -- note Jupyterlab does not support the latex tabular environment (because MathJax does not support it)\n",
    "io = open(\"t2_table.tex\", \"w\");print(io,latexify(table,env=:tabular, fmt = \"%.0f\", latex=false));close(io); # write to tex file using tabular environment\n",
    "\n",
    "#=\n",
    "# using package PrettyTables\n",
    "pretty_table(numbers,headers,title=\"Liabilities for different y\") # show in screen\n",
    "t1 = pretty_table(String,[collect(y_grid) hcat(p_grid...)'],[\"y\", [string(\"node\",i) for i=1:N]...],title=\"Liabilities for different y\",backend = :latex) # make into a latex table\n",
    "io = open(\"t1_table.tex\", \"w\");write(io, \"$t1\");close(io); # write to tex file\n",
    "=#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d522ee",
   "metadata": {},
   "source": [
    "We created a \"more connected\" network and the clearing vectors are indeed different depending on $y$. However, \n",
    "the markdown in liabilities ($\\bar{p}-p$) are the same for all $y$. The reason \n",
    "is that the more connected nodes were the peripheral nodes, and these nodes did not default on their\n",
    "obligations, so there was no default cascade arising from the cycle of liabilities $y$.\n",
    "\n",
    "Let's try again, but now with a bigger shock to the central node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c1af45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shock to the central node of size 94\n",
    "x = [0.0, 0.0, 94.0, 0.0, 0.0]\n",
    "y_grid = 0:100:1000\n",
    "    \n",
    "# initialize variables\n",
    "p_grid = fill([], length(y_grid),1);p_bar_grid = fill([], length(y_grid),1)\n",
    "i=1\n",
    "\n",
    "# compute the clearing vector for each y\n",
    "for y in y_grid \n",
    "    p_grid[i],p_bar_grid[i] = vcat(clearing_vec_yx(y,x))[1]\n",
    "    i=i+1\n",
    "end\n",
    "\n",
    "## show results (just show markdown this time)\n",
    "headers = permutedims([\"y\", [string(\"liab markdown node \",i) for i=1:N]...]); # permutedims is like transpose but, unlike transpose (or adjoint), it works on an array of strings\n",
    "numbers = [collect(y_grid) hcat(p_bar_grid...)'.-hcat(p_grid...)'];\n",
    "\n",
    "# using package Latexify\n",
    "table = vcat(headers,numbers)\n",
    "latexify(table,env=:mdtable, fmt = \"%.0f\", latex=false) |> display # show in screen -- note Jupyterlab does not support the latex tabular environment (because MathJax does not support it)\n",
    "io = open(\"t2_table.tex\", \"w\");print(io,latexify(table,env=:tabular, fmt = \"%.0f\", latex=false));close(io); # write to tex file using tabular environment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4509707",
   "metadata": {},
   "source": [
    "Now we see that the markdown in liabilities is increasing in $y$ for the peripheral nodes. The markdown in liabilities for the central node, however,\n",
    "is unaffected by $y$. This makes sense, since the peripheral nodes have no liabilities with respect\n",
    "to the central node.\n",
    "\n",
    "Let's plot the relation to see how fast total liabilities markdown (summed across all nodes)\n",
    "grow with $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282f98a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot using Gadfly package\n",
    "p1=Gadfly.plot([numbers[:,1] sum(numbers[:,2:end],dims=2)],x=Col.value(1),y=Col.value(2),Geom.line,Guide.xlabel(\"y\"),Guide.ylabel(\"Total liabilities markdown\"))\n",
    "draw(PGF(\"myplot.tex\", 4inch, 3inch), p1) # save using PGF\n",
    "draw(PNG(\"myplot.png\", 4inch, 3inch), p1) # save to PNG\n",
    "draw(PDF(\"myplot.pdf\", 4inch, 3inch), p1) # save to PDF\n",
    "display(p1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c3884d",
   "metadata": {},
   "source": [
    "Looks like the relationship is linear."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36673663",
   "metadata": {},
   "source": [
    "We can also solve the system by using the contraction mapping idea. Instead of \n",
    "solving the nonlinear system in equation (1) using `nlsolve`, we can think of the\n",
    "right-hand side of (1) as a contraction mapping. Given an initial guess $p_0$ for\n",
    "$p$, we apply the contraction mapping to $p_0$ to get $p_1$, and then we apply it\n",
    "successively to get a sequence $p_0,p_1,p_2,...$ that converges to $p$\n",
    "\n",
    "Why would we do this instead of using `nlsolve`? There are a few reasons:\n",
    "- We know that if we pick $p_0=\\bar{p}$, we will always converge to the solution. Other solution methods may not be as robust.\n",
    "- The true solution for $p$ may be well approximated by two or three applications of the contraction map. Applying two or three iterations may be faster than solving the non-linear system.\n",
    "- Automatic differentiation will always work when doing iterated applications of the contraction map, since AD can iterate over functions. Not sure it works if we use `nlsolve`; it should, but don't know if everything inside `nlsolve` is supported.\n",
    "\n",
    "At the very least, we've learned that a good initial guess when using `nlsolve` is $\\bar{p}$.\n",
    "\n",
    "Let's now solve for $p$ using the contraction mapping idea and see how close each iteration is \n",
    "to the true solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add2791d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-define the network (with cycle of liabilities y as in Figure 2)\n",
    "# to compute p, we only need p_bar, A and c\n",
    "\n",
    "y = 100; # arbitrary y for illustration\n",
    "p_bar = [55.0+y, 55.0+y, 140.0, 55.0+y, 55.0+y]; # total liabilities\n",
    "A = [0 y/p_bar[1] 0 0 0; 0 0 0 y/p_bar[1] 0; 10.0/p_bar[3] 10.0/p_bar[3] 0 10.0/p_bar[3] 10.0/p_bar[3]; 0 0 0 0 y/p_bar[1]; y/p_bar[1] 0 0 0 0]; # matrix of relative liabilities\n",
    "c = (50.0, 50.0, 150.0, 50.0, 50.0); # outside assets\n",
    "N = length(c); # number of nodes\n",
    "\n",
    "# solve for the clearing vector using nlsolve as before\n",
    "x = [0.0, 0.0, 94.0, 0.0, 0.0] # shock to the central node of size 94\n",
    "function clearing_vec!(F, p, x)\n",
    "    F .= p.-min.(p_bar,max.(A'*p .+c .- x,0))\n",
    "end\n",
    "sol = nlsolve((F, p)->clearing_vec!(F, p, x),p_bar, autodiff = :forward) \n",
    "p_nlsolve= sol.zero; # the solution to the system\n",
    "@test converged(sol)\n",
    "\n",
    "# solve using contraction mapping idea\n",
    "\n",
    "function contraction(p,x)\n",
    "    # this is the contraction map\n",
    "    min.(p_bar,max.(A'*p .+c .- x,0))\n",
    "end\n",
    "contraction_iter(x, n::Integer) = n <= 0 ? p_bar : contraction(contraction_iter(x,n-1),x) # applies contraction map n times\n",
    "\n",
    "# compute result of applying contraction map a different number of times\n",
    "n_grid = 0:30\n",
    "p_iter = [sum(contraction_iter(x,n)) for n in n_grid];\n",
    "\n",
    "# plot sum(p) vs number of iterations to see convergence\n",
    "layer1=layer(p_iter,x=Col.index,y=Col.value,Geom.point,Theme(default_color=colorant\"orange\"))\n",
    "layer2=layer(fill(sum(p_nlsolve),length(n_grid)),x=Col.index,y=Col.value,Geom.line)\n",
    "p1=Gadfly.plot(layer1,layer2,Guide.xlabel(\"iteration number\"),Guide.ylabel(\"p\"), Guide.manual_color_key(\"\",[\"Contraction map\",\"True solution\"],[\"orange\",\"deepskyblue\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d97f34",
   "metadata": {},
   "source": [
    "For this particular case, applying the contraction map 10 times essentially gets us to the solution.\n",
    "\n",
    "We note that the fixed point of the contraction is a solution to the original system (1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d1a176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute fixed point of contraction and show it is equal to the solution of (1)\n",
    "@test nlsolve(p-> p.-contraction(p,x),p_bar, autodiff = :forward).zero == p_nlsolve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6043e793",
   "metadata": {},
   "source": [
    "Systemic Losses\n",
    "---------------\n",
    "\n",
    "To quantify network spillovers, we need to have a measure of the total systemic impact of a shock. We use the definition of systemic\n",
    "losses in [Glasserman and Young (2015)](https://www.sciencedirect.com/science/article/pii/S0378426614000600#!), who state:\n",
    "\n",
    "    There appears to be no commonly accepted measure of systemic impact in the prior literature. Eisenberg and Noe (2001) suggest that it is the number of waves of default that a given shock induces in the network. Other authors have suggested that the systemic impact should be measured by the aggregate loss of bank capital; see for example Cont et al. (2010). Still others have proposed the total loss in value of only those nodes external to the financial sector, i.e. firms and households.\n",
    "    Here we shall take the systemic impact of a shock to be the total loss in [asset] value summed over all nodes, including nodes corresponding to financial entities as well as those representing firms and households. \n",
    "\n",
    "In terms of the variables of the network, the total loss in asset value summed over all nodes when a shock $x$ hits the network is\n",
    "\n",
    "\\begin{equation*}\n",
    "    L(x) = \\sum_{i=1}^{N} x_i + \\bar{p}_i -p_i(x) \\label{eq:sys} \\tag{2}\n",
    "\\end{equation*}\n",
    "\n",
    "The first term represents the direct loss, while the second term represents the indirect loss in value from reductions in payments by the nodes to other nodes and to the external sector."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e92e63",
   "metadata": {},
   "source": [
    "The Disconnected Network\n",
    "------------------------\n",
    "\n",
    "To quantify the amplification of losses stemming from the network\n",
    "structure –as opposed to the initial losses from exogenous shock to\n",
    "outside assets– we compare expected losses for the system (the network\n",
    "plus the outside sector) to the losses in a hypothetical system in which\n",
    "all connections inside the network have been severed. Both networks are\n",
    "subject to the same distribution of exogenous shocks to outside assets,\n",
    "and to no other shocks. We create this hypothetical *disconnected*\n",
    "system by removing all connections between nodes inside the original\n",
    "network but keeping the links with the outside sector intact. We also\n",
    "assume the net worth at each node remains unchanged by creating, for\n",
    "each node, a fictitious claim to the outside sector equal in value to\n",
    "the net value of all the connections that were removed. Depending on the\n",
    "sign of the net value of removed connections, the new fictitious claim\n",
    "can be an asset or a liability. If it is an asset, we assume it is not\n",
    "subject to the shocks to outside assets to keep the set of assets\n",
    "initially shocked identical to that of the original network. If the new\n",
    "fictitious claim is a liability, we assume it has the same priority as\n",
    "all other liabilities. In case of default, the new fictitious liability\n",
    "gets haircut pro rata just like all other non-fictitious liabilities,\n",
    "and any “losses” imposed on that obligation are counted towards the\n",
    "value of total system losses. Figure\n",
    "<a href=\"#Fig3\">Figure 3</a>\n",
    "shows the disconnected version of network displayed in Figure\n",
    "<a href=\"#Fig1\">Figure 1</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5a1296",
   "metadata": {},
   "source": [
    "<figure>\n",
    "    <img src='../../paper/fig2_networkDisconnected.png' alt='A disconnected network' id=\"Fig3\" />\n",
    "    <figcaption>Figure 3: A disconnected network</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa15853",
   "metadata": {},
   "source": [
    "To plot the disconnected network, we create the fictitious assets and liabilities and use a relative liabilities matrix $A$ with \n",
    "all entries equal to zero.|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e7551c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the disconnected network from Figure 3\n",
    "\n",
    "b_fict = max.(0,f.-d); # fictitious outside liabilities\n",
    "c_fict = max.(0,d.-f); # fictitious outside assets\n",
    "\n",
    "Adis_pre1 = vcat(hcat(zeros(size(A)),Diagonal([c...]),zeros(N,N)),hcat(vcat(zeros(N,N),Diagonal([b...])),zeros(2N,2N))); # relative liabilities matrix including outside sector\n",
    "Adis_pre2 = hcat(vcat(Adis_pre1,hcat(vcat(zeros(N,N),Diagonal([c_fict...])),zeros(2N,size(Adis_pre1,2)-N))),hcat(vcat(Diagonal([b_fict...]),zeros(size(Adis_pre1,1)+N,size(b_fict,1))),zeros(size(Adis_pre1,1)+2N,size(c_fict,1)))) # add fictitious nodes\n",
    "\n",
    "# remove fictitious nodes with zero assets or zero liabilities\n",
    "keep1 = sum(Adis_pre2,dims=1).+sum(Adis_pre2,dims=2)'  # sum of assets and liabilities for each node\n",
    "keep2 = findall(x->x != 0,keep1); # index equal to 1 if sum of assets and liabilities is not zero\n",
    "keep3 = last.(Tuple.(keep2)); # convert to use in Adis\n",
    "\n",
    "# remove nodes\n",
    "Adis = Adis_pre2[keep3,keep3] \n",
    "b_fict = filter(x->x!=0,b_fict)\n",
    "c_fict = filter(x->x!=0,c_fict)\n",
    "Nall = size(Adis,1) # number of nodes\n",
    "\n",
    "# plot it\n",
    "graphplot(LightGraphs.DiGraph(Adis),\n",
    "          nodeshape=:circle,\n",
    "          markersize = 0.12,\n",
    "          node_weights = [vcat([w...],[b...],[c...],[b_fict...],[c_fict...])...].^(1/30),\n",
    "          markercolor = :white, #range(colorant\"yellow\", stop=colorant\"red\", length=N+1),\n",
    "          names =  trunc.(Int,hcat(w...,b...,c...,b_fict...,c_fict...)),\n",
    "          fontsize = 8,\n",
    "          edgecolor = hcat(:red,:red,:red,:black,:red,:red,:red,:red,:red,:red,:red,:black,:black,:black,:black),\n",
    "          linestyle = hcat(:dashdot,:dashdot,:dashdot,:dot,:dashdot,:dashdot,:dashdot,:dashdot,:dashdot,:dashdot,:dashdot,:dashdot,:dashdot,:dashdot,:dashdot,:dashdot,:dot,:dot,:dot,:dot),\n",
    "          edgewidth = (s,d,w)->0.03*Adis[s,d],\n",
    "          arrow=true,\n",
    "          method= :stress,\n",
    "          curves=false,\n",
    "          edgelabel= trunc.(Int,Adis),\n",
    "          axis_buffer=0.1,\n",
    "          edgelabel_offset=0,\n",
    "          shorten=0,\n",
    "          edge_label_box=true,\n",
    "          layout_kw= Dict(:iterations => 10000),\n",
    "          size=(700,700)\n",
    "    # attributes here: https://docs.juliaplots.org/latest/generated/graph_attributes/\n",
    "    # method `:spectral`, `:sfdp`, `:circular`, `:shell`, `:stress`, `:spring`, `:tree`, `:buchheim`, `:arcdiagram` or `:chorddiagram`.\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bb5a1f",
   "metadata": {},
   "source": [
    "An Upper Bound on Network Spillovers\n",
    "------------------------------------\n",
    "\n",
    "We are interested in whether the expected system losses in our\n",
    "real-world, interconnected system, are substantially greater than those\n",
    "in the hypothetical *disconnected* system, where node connections have\n",
    "been excised. We define $R$ to be the ratio of expected losses for the\n",
    "actual network to the expected losses in the disconnected network. That\n",
    "is, if $L(x)$ denotes total system losses defined as in Equation 2,\n",
    "\n",
    "$$R=\\frac{E(L_{\\text{Actual}}(x))}{E(L_\\text{Disconnected}(x))}$$\n",
    "\n",
    "where the expectation is computed with respect to the distribution of\n",
    "the shock $x$. The value of $R$ gives the relative magnitude of additional losses\n",
    "imposed on the system because of the interconnected structure of the\n",
    "network - to wit, network effect losses. With perfect information on the\n",
    "bilateral claims in the system, this ratio could be calculated exactly\n",
    "in response to a variety of shocks by using the algorithm to compute the\n",
    "set of node payments that clear the system (i.e. follow the system’s\n",
    "rules of limited liability and pro rata allocation). In the United\n",
    "States' financial system, detailed and publicly-available data on\n",
    "bilateral obligations between financial firms does not exist.\n",
    "\n",
    "The main result in [Glasserman and Young (2015)](https://www.sciencedirect.com/science/article/pii/S0378426614000600#!) is that a useful upper-bound on $R$ can be derived\n",
    "without any information regarding each node’s bilateral claims together with two \n",
    "mild assumptions regarding the shocks.\n",
    "We call this upper-bound $B$. The first assumption regarding the shocks is on their\n",
    "distribution. The distribution cannot be too fat-tailed.[<sup>3</sup>](#fn3).The second\n",
    "assumption is that the shocks are \"homogeneous\" with respect to $c$: If $F(x_1,x_2,...,x_N)$ is\n",
    "the cdf of $x=(x_1,x_2,...,x_N)$, then we can write \n",
    "$F(x_1,x_2,...,x_N)=G(x_1/c_1,x_2/c_2,...,x_N/c_N)$ for some symmetric cdf G. When these two assumptions hold, $B$ can be calculated using node-specific information only.\n",
    "\n",
    "In practice, we deal with the homogeneity assumption by writing $x_i = \\tilde{x}_i c_i$ for some shock \n",
    "$\\tilde{x}_i \\in [0,1]$ whose cdf is not restricted to be homogeneous (with slight abuse\n",
    "of notation, we use $x$ for both $x$ and $\\tilde{x}_i$).\n",
    "\n",
    "More specifically, [Glasserman and Young (2015)](https://www.sciencedirect.com/science/article/pii/S0378426614000600#!) show that $B$\n",
    "depends only on each node’s total outside assets $c$, each firm’s\n",
    "probability of default due to direct shocks to outside assets $\\delta$,\n",
    "and the maximum *liability connectivity* among nodes in the system\n",
    "$\\beta^+$. Each node’s liability connectivity is defined as its ratio of\n",
    "inside liabilities to total liabilities. The formula for $B$ is\n",
    "\n",
    "$$\\label{eq:B}\n",
    "B=1+\\frac{1}{(1-\\beta ^{+})}\\frac{\\sum_{i \\in S} {\\delta _{i}c_{i}}}{\\sum_{i \\in S}{c_{i}}},$$\n",
    "\n",
    "where \n",
    "\n",
    "$$\\begin{aligned}\n",
    "\\delta_{i} &:\\text{probability of default from outside shocks for node }i, \\\\\n",
    "c_{i} &:\\text{the dollar value of outside assets for node }i, \\\\\n",
    "\\beta ^{+} &:\\text{maximum liability connectivity, i.e., }\\beta^{+}=\\max_{i \\in S}\\beta _{i}\\text{, with } \\beta_i=\\text{the fraction of } \\\\\n",
    "& \\text{firm i's liabilities held by other nodes in the networks}, \\\\\n",
    "S &:\\text{Set of financial institution nodes within the network.}\\end{aligned}$$\n",
    "\n",
    "The upper bound $B$ for network spillovers is increasing in the maximum\n",
    "financial connectivity of the system, $\\beta ^{+}$, and in the quantity\n",
    "$\\sum {\\delta _{i}c_{i}}/\\sum {c_{i}}$, most-easily interpretable as a\n",
    "weighted average probability of default for the system (with each firm’s\n",
    "weight given by its share of total outside assets). When $\\beta ^{+}$ is\n",
    "close to $1$, aggregate financial connectivity is high and any initial\n",
    "shock to outside assets has the potential to be transmitted broadly\n",
    "across the network. In contrast, when $\\beta ^{+}$ is close to zero, any\n",
    "initial shock dissipates quickly and expected losses should be similar\n",
    "to those in a truly disconnected network.\n",
    "\n",
    "For most systems calibrated to real-world data, previous studies have\n",
    "found that the upper bound $B$ is small. For example, picking\n",
    "$\\beta ^{+}=0.8$ and $\\delta _{i}=1$ percent for all nodes $i$, we get\n",
    "$B=1+0.01/(1-0.8)=1.05$. This means that the connected system has\n",
    "expected losses that are at most $5$ percent larger than those in the\n",
    "system of isolated nodes. [Glasserman and Young (2015)](https://www.sciencedirect.com/science/article/pii/S0378426614000600#!) \n",
    "provide an example for European banks using data from the\n",
    "the 2011 European Banking Authority stress test. They find \n",
    "an even smaller upper bound of $1.0175$. If the *upper bound*\n",
    "is low, then the actual ratio $R$ is also low, with the implication\n",
    "that network default spillovers for financial institutions is not, by itself,\n",
    "a big source of amplification of shocks.\n",
    "\n",
    "Unlike these examples, when we use data for the US, we find that the bound \n",
    "$B$ can be large in certain periods, especially around the 2008 financial crisis. \n",
    "Figure 4 shows the empirical estimate we have for $B-1$. We see that the\n",
    "bound exceeds ten percent for a number of years and can reach almost forty percent\n",
    "at its peak.\n",
    "\n",
    "<figure>\n",
    "    <img src='../../output/NVI_benchmark.png' alt='Example of a network' id=\"Fig4\" />\n",
    "    <figcaption>Figure 4: Estimated upper bound $B$ using all US financial firms </figcaption>\n",
    "</figure>\n",
    "\n",
    "Now, a large bound $B$ still leaves unresolved the issue of how large $R$ is. We had discussed\n",
    "that a low upper bound necessarily means spillovers are small. But what can we say if the \n",
    "upper bound is large? The actual ratio $R$ can be anywhere between zero and $B$.\n",
    "\n",
    "Our main goal\n",
    "--------------\n",
    "\n",
    "Our main goal is to estimate the range of values for $R$ that are consistent \n",
    "with our empirical (node-specific) data. If the range is not too wide and close to\n",
    "$B$, then we have a stronger case for spillovers being large. If the range is not too\n",
    "wide but close to zero, then we have evidence against spillovers being large. Last,\n",
    "the range can be wide, in which case we do not have a lot of additional information.\n",
    "\n",
    "The empirical data that we observe are the values of $w_i, c_i, assets_i, \\bar{p}_i, b_i, \\delta_i$ for a subset of nodes. The subset of nodes for which we observe $w_i$ is not the same\n",
    "as the subset for which we observe $c_i$, and the same for all other variables. So for\n",
    "example, we may have all of $w_1, c_1, assets_1, \\bar{p}_1, b_1, \\delta_1$ for firm $i=1$, only $w_2, c_2, \\delta_2$ for firm $i=2$, and only $assets_i$  for $i=3$. \n",
    "\n",
    "Conceptually, what we want to do is to look at all possible networks whose values for\n",
    "$w_i, c_i, assets_i, \\bar{p}_i, b_i, \\delta_i$ match those from the data. Then we compute the highest and lowest $R$ across all of these networks.\n",
    "\n",
    "Of course, we cannot look at all possible networks. We do not observe $A$, which is $N \\times N$, and looking over $N^2$ values is just not feasible (ok, it is not exactly $N^2$ because there are some restrictions, like the diagonal has to be all zeros, but the restrictions are not enough to bring the number down enough). So instead of really looking at all possible networks, we think of the task as a maximization or minimization problem, where we maximize or minimize $R$ subject to the constraints that observed data is respected and network relations hold (for example, a \"network relation\" is that outside assets cannot be larger than total assets)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c837bb",
   "metadata": {},
   "source": [
    "Bankruptcy costs\n",
    "----------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688938ac",
   "metadata": {},
   "source": [
    "Optimization\n",
    "-------------\n",
    "\n",
    "Let's be more precise. The optimization problem is the following.\n",
    "\n",
    "Choose $p_{i}(x), c_{i}, b_{i}, \\delta_i$ for $i=1,...,N$, $a_{ij}$ for $i,j=1,...,N$, and a cumulative distribution function $G(x_1,x_2,...,x_N)$ where $x_i \\in [0,1]$ for $i=1,2,...,N$, in order to maximize\\minimize\n",
    "\n",
    "$$\\begin{equation}\n",
    "\\mathbb{E}\\left[ \\sum_{i=1}^{N}\\left( c_{i}x_{i}+\\bar{p}_i-p_{i}\\left( x\\right) \\right) %\n",
    "\\right] \n",
    "\\end{equation}$$\n",
    "\n",
    "subject to the following constraints:\n",
    "\n",
    "1. Box constraints (sometimes also called \"bound\" constraints)\n",
    "$$\\begin{aligned}\n",
    "0 &\\leq p_{i} \\leq \\bar{p}_{i} & \\text{,} &\\text{ for }i=1,..,N \\\\\n",
    "0 &\\leq c_{i} \\leq assets_{i} & \\text{,} &\\text{ for }i=1,..,N \\\\\n",
    "0 &\\leq b_{i} \\leq \\bar{p}_{i} & \\text{,} &\\text{ for }i=1,..,N \\\\\n",
    "0 &\\leq a_{ij} \\leq 1 & \\text{,} & \\text{ for }i,j=1,..,N.\n",
    "\\end{aligned}$$\n",
    "\n",
    "2. Linear constraints\n",
    "$$\\begin{aligned}\n",
    "\\sum_{j=1}^{n}a_{ji}\\bar{p}_{j} &=d_{j}\\text{,} &\\text{ for }i=1,..,N \\\\\n",
    "\\bar{p}_{i}\\sum_{j=1}^{n}a_{ij} &=f_{i}\\text{,} &\\text{ for }i=1,..,N \\\\\n",
    "\\end{aligned}$$\n",
    "\n",
    "3. Complementarity constraints (sometimes also called \"equilibrium\" constraints)\n",
    "$$\\begin{aligned}\n",
    "a_{ii} &=0\\text{,} &\\text{ for }i=1,..,N \\\\\n",
    "a_{ij}a_{ji} &=0 \\text{,} &\\text{ for }i=1,..,N\\text{ and }j<i.\n",
    "\\end{aligned}$$\n",
    "\n",
    "4. Non-linear constraints\n",
    "$$\\begin{aligned}\n",
    "p_{i}(x) =\\min \\left[ \\bar{p}_{i},\\max \\left[ 0, \\sum_{j=1}^{n}a_{ji}p_{j}(x) +(1-x_{i})c_{i}\\right] \\right] &\\text{ for } i=1,..,N\n",
    "\\end{aligned}$$\n",
    "\n",
    "5. Probabilistic constraints\n",
    "$$\\begin{aligned}\n",
    "\\delta_i = Pr(c_i x_i\\geq w_i) &\\text{ for } i=1,..,N\n",
    "\\end{aligned}$$\n",
    "where $x_i \\in [0,1]$ has cdf $G(x_1,x_2,...,x_N)$.\n",
    "\n",
    "Some comments on this optimization problem:\n",
    "\n",
    "1. We would love to solve this problem for $N=150$, which is the approximate number of nodes in the data. However, I would be very happy if we can solve this using the largest $N=50$ nodes. At a minimum, we need $N=25$.\n",
    "\n",
    "2. Computing the expectation in the objective function is the hardest part of the problem in terms of the raw amount of computation. We can always write the expectation as an $N$-dimensional integral. If we wanted to break the domain $[0,1]^N$ into small hypercubes to approximate the integral with sums, and we approximate the interval $[0,1]$ with a grid of ten points, we would need $10^N$ hypercubes. Even for $N=10$, we get too big a space. The most common method to compute multi-dimensional integrals is by using Monte Carlo simulations. But there are other ideas out there as well.\n",
    "\n",
    "3. Complementarity constraints are easy to understand/visualize: in the $N \\times N$ matrix $A$, if some $a_{ij}$ element is non-zero, then the element that is symmetric with respect to the diagonal, $a_{ji}$, has to be zero. So $A$ has at least half of its non-diagonal elements equal to zero (and the diagonal elements all equal to zeros). However, they introduce some problems. First, there is a combinatorial aspect to them. We can imagine first picking which elements are non-zero below the main diagonal. The choice imposes some zeros above the diagonal. Once we know which elements must be zero, we optimize over all the other ones ignoring the complementarity constraints. But there are many, many ways to pick the non-zero elements in the first place! Second, most \"normal\" solvers, especially those that rely heavily on everything being smooth, have a very difficult time solving these complementarity constraints without any special treatment. Their derivatives blow up close to zero, and solutions are always at a corner for at least half the variables. Third, they are the only constraints that destroy the \"convexity\" of the problem. Without these constraints, we could re-write the problem so that the objective is convex and the constraint set is also convex, which are much much easier and faster to solve numerically.\n",
    "\n",
    "4. The choice of the cdf G means that our problem is infinite dimensional: we have to choose an entire function, not just a finite set of numbers. If we knew G, then the problem is finite-dimensional.\n",
    "\n",
    "5. Probabilistic constraints can be tricky for automatic differentiation. If we are doing a Monte Carlo to compute the expectation in the objective function, we need to draw from G. But we are also optimizing over G. This has two implications. First, every time we change G, we need to change the distribution we use for Monte Carlo. Second, it may be tricky to compute the \"derivative\" of the objective function with respect to G. For each small deviation from the current G, it seems like we would need to do an entire new Monte Carlo run to find how the objective changes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a28949",
   "metadata": {},
   "source": [
    "The following [slides](NetworkContagion_presentation.pdf) work out an example in which the initial shock to the \n",
    "outside assets of the central node is $94$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ad35de",
   "metadata": {},
   "source": [
    "Footnotes\n",
    "---------\n",
    "\n",
    "[1] <span id=\"fn1\">More technically, we consider shocks that have an “increasing\n",
    "failure rate\" (IFR). A random variable with distribution function\n",
    "$G\\left( x\\right)$ and density $g\\left( x\\right)$ is said to have an IFR\n",
    "if $g\\left( x\\right) /(1-G\\left( x)\\right)$ is an increasing function of\n",
    "$x$ . This family encompasses the normal, exponential, and uniform\n",
    "distributions. There are no restrictions on the correlation structure of\n",
    "shocks.\n",
    "\n",
    "In addition, the joint distribution of potential shocks is assumed to be\n",
    "invariant to scale (homogeneous in assets). For example, if total assets\n",
    "of a node double, expected losses are assumed to also double.</span>\n",
    "\n",
    "[2] <span id=\"fn2\">In this section, we have used the words “small” and “large” to\n",
    "characterize different levels of the $NVI$ without being explicit about\n",
    "their meaning. This was a deliberate choice, since the model provides no\n",
    "welfare analysis and no other indication on how to evaluate the overall\n",
    "magnitude of the $NVI$. In short, the burden of interpreting what\n",
    "constitutes small or large values for the $NVI$ is the policymaker’s.</span>\n",
    "\n",
    "[3] <span id=\"fn3\">The bounds derived by are actually stronger than this - applying to\n",
    "the probability of node $i$ causing default through contagion to a given\n",
    "*group* of firms.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d27cd9",
   "metadata": {},
   "source": [
    "Re-write problem\n",
    "----\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09ecd4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra, DataFrames, XLSX, Missings, Test, SpecialFunctions,  SparseArrays , Random\n",
    "using JuMP, Ipopt,  Distributions, DistributionsAD, SpecialFunctions, NLsolve, Random\n",
    "using Quadrature, Cubature, Cuba, QuadGK\n",
    "#using EAGO, Alpine, Juniper, NLopt, Pavito, SCIP, GLPK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "994bf3e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m867×12 DataFrame\u001b[0m\n",
      "\u001b[1m Row \u001b[0m│\u001b[1m nm_short                     \u001b[0m\u001b[1m qt_dt \u001b[0m\u001b[1m tkr  \u001b[0m\u001b[1m delta     \u001b[0m\u001b[1m delta_alt   \u001b[0m\u001b[1m beta     \u001b[0m\u001b[1m w         \u001b[0m\u001b[1m c        \u001b[0m\u001b[1m assets   \u001b[0m\u001b[1m nvi_benchmark \u001b[0m\u001b[1m p_bar    \u001b[0m\u001b[1m b        \u001b[0m\n",
      "\u001b[1m     \u001b[0m│\u001b[90m Any                          \u001b[0m\u001b[90m Any   \u001b[0m\u001b[90m Any  \u001b[0m\u001b[90m Any       \u001b[0m\u001b[90m Any         \u001b[0m\u001b[90m Any      \u001b[0m\u001b[90m Any       \u001b[0m\u001b[90m Any      \u001b[0m\u001b[90m Any      \u001b[0m\u001b[90m Any           \u001b[0m\u001b[90m Any      \u001b[0m\u001b[90m Any      \u001b[0m\n",
      "─────┼───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "   1 │ JPMORGAN CHASE & CO           195    JPM   0.0106652  0.00862097   0.56278   0.168059   1.45164   2.17505   11.0931        2.00699   0.877498\n",
      "   2 │ CITIGROUP                     195    C     0.0647046  0.0475393    0.481591  0.144022   1.38565   1.93847   11.0931        1.79445   0.930258\n",
      "   3 │ BANK OF AMER CORP             195    BAC   0.016278   0.0117393    0.50803   0.17871    1.51681   1.82207   11.0931        1.64336   0.808482\n",
      "   4 │ WELLS FARGO & CO              195    WFC   0.0047069  0.00462975   0.397362  0.102316   1.15898   1.30964   11.0931        1.20732   0.727579\n",
      "   5 │ GOLDMAN SACHS GROUP INC       195    GS    0.0253824  0.0282284   \u001b[90m missing  \u001b[0m 0.04922   \u001b[90m missing  \u001b[0m 1.08177  \u001b[90m missing       \u001b[0m 1.03255  \u001b[90m missing  \u001b[0m\n",
      "   6 │ AMERICAN INTERNATIONAL GROUP  195    AIG   0.057924   0.0455341   \u001b[90m missing  \u001b[0m 0.082995  \u001b[90m missing  \u001b[0m 1.02224  \u001b[90m missing       \u001b[0m 0.939242 \u001b[90m missing  \u001b[0m\n",
      "   7 │ MORGAN STANLEY                195    MS    0.0892237  0.131335    \u001b[90m missing  \u001b[0m 0.035765  \u001b[90m missing  \u001b[0m 0.987403 \u001b[90m missing       \u001b[0m 0.951638 \u001b[90m missing  \u001b[0m\n",
      "   8 │ MERRILL LYNCH  CO INC         195    BAC2  0.0602485  0.0550379   \u001b[90m missing  \u001b[0m 0.0406288 \u001b[90m missing  \u001b[0m 0.87578  \u001b[90m missing       \u001b[0m 0.835151 \u001b[90m missing  \u001b[0m\n",
      "   9 │ METLIFE                       195    MET   0.0081233  0.00663113   0.514254  0.0239866  0.373146  0.501678  11.0931        0.477692  0.232037\n",
      "  10 │ PRUDENTIAL FINANCIAL INC      195    PRU   0.0242412  0.0192051   \u001b[90m missing  \u001b[0m 0.018699  \u001b[90m missing  \u001b[0m 0.460398 \u001b[90m missing       \u001b[0m 0.441699 \u001b[90m missing  \u001b[0m\n",
      "  11 │ HARTFORD FINANCIAL SERVICES   195    HIG   0.0401791  0.0436828   \u001b[90m missing  \u001b[0m 0.012557  \u001b[90m missing  \u001b[0m 0.311485 \u001b[90m missing       \u001b[0m 0.298928 \u001b[90m missing  \u001b[0m\n",
      "  ⋮  │              ⋮                  ⋮     ⋮        ⋮           ⋮          ⋮          ⋮         ⋮         ⋮            ⋮           ⋮         ⋮\n",
      " 857 │ MANHATTAN BRIDGE CAPITAL INC  195    LOAN  0.0023348  0.00159594  \u001b[90m missing  \u001b[0m 7.016e-6  \u001b[90m missing  \u001b[0m 7.173e-6 \u001b[90m missing       \u001b[0m 1.57e-7  \u001b[90m missing  \u001b[0m\n",
      " 858 │ GLOBAL HEALTHCARE REIT        195    GBCS  0.104583   0.0862715   \u001b[90m missing  \u001b[0m 4.222e-6  \u001b[90m missing  \u001b[0m 7.154e-6 \u001b[90m missing       \u001b[0m 2.932e-6 \u001b[90m missing  \u001b[0m\n",
      " 859 │ NETWORK-1 TECHNOLOGIES INC    195    NTIP  0.0012227  0.000952608 \u001b[90m missing  \u001b[0m 4.845e-6  \u001b[90m missing  \u001b[0m 4.969e-6 \u001b[90m missing       \u001b[0m 1.24e-7  \u001b[90m missing  \u001b[0m\n",
      " 860 │ SECOND STREET CAPITAL INC     195    CTON  0.299511   0.241776    \u001b[90m missing  \u001b[0m 1.026e-6  \u001b[90m missing  \u001b[0m 4.014e-6 \u001b[90m missing       \u001b[0m 2.988e-6 \u001b[90m missing  \u001b[0m\n",
      " 861 │ CAMBRIDGE HOLDINGS LTD        195    CDGD  0.0476988  0.0492359   \u001b[90m missing  \u001b[0m 1.313e-6  \u001b[90m missing  \u001b[0m 1.967e-6 \u001b[90m missing       \u001b[0m 6.54e-7  \u001b[90m missing  \u001b[0m\n",
      " 862 │ NORAM CAPITAL HOLDINGS INC    195    NRMH  0.244393   0.242803    \u001b[90m missing  \u001b[0m 1.09e-6   \u001b[90m missing  \u001b[0m 1.628e-6 \u001b[90m missing       \u001b[0m 5.38e-7  \u001b[90m missing  \u001b[0m\n",
      " 863 │ UMC INC                       195    UMCN  0.126107   0.225341    \u001b[90m missing  \u001b[0m 4.59e-7   \u001b[90m missing  \u001b[0m 9.66e-7  \u001b[90m missing       \u001b[0m 5.07e-7  \u001b[90m missing  \u001b[0m\n",
      " 864 │ RECEIVABLE ACQ MGMT -OLD      195    CSEI  0.0594649  0.039179    \u001b[90m missing  \u001b[0m 4.69e-7   \u001b[90m missing  \u001b[0m 5.22e-7  \u001b[90m missing       \u001b[0m 5.3e-8   \u001b[90m missing  \u001b[0m\n",
      " 865 │ NOCOPI TECHNOLOGIES INC       195    NNUP  0.0232885  0.0182395   \u001b[90m missing  \u001b[0m 0.0       \u001b[90m missing  \u001b[0m 4.49e-7  \u001b[90m missing       \u001b[0m 4.49e-7  \u001b[90m missing  \u001b[0m\n",
      " 866 │ ST LAWRENCE SEAWAY CORP-OLD   195    CRBO  0.0044543  0.00446339  \u001b[90m missing  \u001b[0m 9.5e-8    \u001b[90m missing  \u001b[0m 9.9e-8   \u001b[90m missing       \u001b[0m 4.0e-9   \u001b[90m missing  \u001b[0m\n",
      " 867 │ INVENT VENTURES INC           195    IDEA  0.0152749  0.0119091   \u001b[90m missing  \u001b[0m 3.0e-9    \u001b[90m missing  \u001b[0m 3.5e-8   \u001b[90m missing       \u001b[0m 3.2e-8   \u001b[90m missing  \u001b[0m\n",
      "\u001b[36m                                                                                                                                     845 rows omitted\u001b[0m"
     ]
    }
   ],
   "source": [
    "## load data\n",
    "\n",
    "xf = XLSX.readxlsx(\"node_stats_forsimulation_all.xlsx\") \n",
    "data = vcat( [(XLSX.eachtablerow(xf[s]) |> DataFrames.DataFrame) for s in XLSX.sheetnames(xf)]... ) #for s in XLSX.sheetnames(xf) if (s!=\"Aggregates Composition\" && s!=\"Dealer Aggregates\" && s!=\"Approx Aggregates\")\n",
    "unique!(data) # delete duplicate rows, use `nonunique(data)` to see if there are any duplicates\n",
    "data = data[isequal.(data.qt_dt,195), :] # keep quarter == 195 = 2008q4\n",
    "sort!(data, :assets, rev = true)\n",
    "#data = data[1:N,:] # keep small number of nodes, for testing\n",
    "#N = size(data,1) # number of nodes\n",
    "units = 1e6;\n",
    "data[:,[:w, :c, :assets, :p_bar, :b]] .= data[!,[:w, :c, :assets, :p_bar, :b]]./units\n",
    "# data.b[:] .= missing\n",
    "# data.c[:] .= missing\n",
    "\n",
    "col_with_miss = names(data)[[any(ismissing.(col)) for col = eachcol(data)]] # columns with at least one missing\n",
    "data_nm = coalesce.(data, data.assets/1.5) # replace missing by a value\n",
    "nm_c = findall(x->x==0,ismissing.(data.c))\n",
    "nm_b = findall(x->x==0,ismissing.(data.b))\n",
    "dropmissing(data, [:delta, :delta_alt, :w, :assets, :p_bar]) # remove type missing\n",
    "\n",
    "# when we optimize, we optimize over c and b, and fix the non-missing b and c from the data\n",
    "#[fix(c[i], data.c[i]; force=true) for i  in nm_c] #fixing c to data\n",
    "#[fix(b[i], data.b[i]; force=true) for i  in nm_b] #fixing b to data\n",
    "\n",
    "names(data) # column names\n",
    "describe(data)\n",
    "show(data, allcols = true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ed8700c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# p_bar = data_nm.p_bar\n",
    "# assets = data_nm.assets\n",
    "\n",
    "## fixed point\n",
    "# x0 = [1;1]\n",
    "# function contraction(p,x)\n",
    "#    min.(p_bar, max.(A'*p .+ c .- x.*c,0))\n",
    "# end\n",
    "# contraction_iter(x, n::Integer) = n <= 0 ? p_bar  : contraction(contraction_iter(x,n-1),x)\n",
    "\n",
    "# aux = Variable(1,1)\n",
    "# theta = 1.1\n",
    "# constraint2 =(theta*aux>=A[1,2])\n",
    "# constraint3 = (theta*(1-aux)>=A[2,1])\n",
    "\n",
    "#p = Variable(2,Positive())\n",
    "\n",
    "################################\n",
    "\n",
    "N=3\n",
    "#temp = convert(Array{Float32},data[:,[:delta, :delta_alt, :w, :assets, :p_bar]])\n",
    "const T = Float32\n",
    "temp = Array{T}(data[1:N,[:delta, :delta_alt, :w, :assets, :p_bar]])\n",
    "const delta = copy(temp[:,1]); \n",
    "const delta_alt = copy(temp[:,2]);\n",
    "const w = copy(temp[:,3]); \n",
    "const assets= copy(temp[:,4]);\n",
    "const p_bar = copy(temp[:,5]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "805fcfec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×18 SparseMatrixCSC{Float32, Int64} with 3 stored entries:\n",
       "⠀⠀⠀⠀⠀⠀⠀⠈⠉"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const γ = T(0)\n",
    "const M = N^2+3*N\n",
    "\n",
    "rng =  Random.seed!(123)\n",
    "x = rand(T, N)\n",
    "Ex = zeros(T,N) #ones(T,N)/2 # expectation of x\n",
    "\n",
    "# upper and lower bounds\n",
    "# low<=z<=upp\n",
    "const low = spzeros(T,M)\n",
    "const upp = vcat(ones(T,N^2),p_bar,assets,p_bar)\n",
    "\n",
    "# linear constraints\n",
    "H₁ = spzeros(T,M,M)\n",
    "h₁₁ᵀ = hcat(sparse(kron(Matrix{T}(I,N,N),p_bar')))\n",
    "h₁ᵀ = hcat(h₁₁ᵀ,spzeros(T,N,N),sparse(I,N,N),spzeros(T,N,N))\n",
    "q₁ = assets\n",
    "\n",
    "H₂ = spzeros(T,M,M)\n",
    "h₂₁ᵀ = repeat(spdiagm(p_bar),1,N)\n",
    "h₂ᵀ = hcat(h₂₁ᵀ,sparse(I,N,N),spzeros(T,N,N),spzeros(T,N,N))\n",
    "q₂ = p_bar\n",
    "\n",
    "# hᵀz=q\n",
    "const hᵀ = vcat(h₁ᵀ,h₂ᵀ)\n",
    "const q = vcat(q₁,q₂)\n",
    "\n",
    "# quadratic constraints\n",
    "li = LinearIndices((N,N))\n",
    "liᵀ= transpose(li)\n",
    "id = li[tril!(trues(N,N), 0)]\n",
    "idᵀ = liᵀ[tril!(trues(N,N), 0)]\n",
    "H₃= sparse(vcat(id,idᵀ),vcat(idᵀ,id),T(0.5),M,M)\n",
    "h₃ = spzeros(T,M)\n",
    "q₃ = spzeros(T,1)\n",
    "\n",
    "# zᵀHz = 0\n",
    "const H = H₃\n",
    "\n",
    "# nonlinear constraints\n",
    "# [h₄₄ᵀ[i]z=min{p_bar[i],max{zᵀH₄[i]z+h₄ᵀ[i]z+q₄[i],0}} for i=1,2,...,N]\n",
    "# note: h₄ᵀ[i] depends on x\n",
    "const H₄  = [sparse( vcat(N*(i-1)+1:N*i,M-N+1:M), vcat(M-N+1:M,N*(i-1)+1:N*i), (1+γ)*ones(T,2*N)/2,M,M) for i=1:N] # H₄⁽ⁱ⁾=H₄[i]\n",
    "h₄ᵀ = [sparse([1],[N^2+N+i],(1+γ)*(T(1)-x[i]),1,M) for i=1:N] # h₄ᵀ⁽ⁱ⁾=h₄ᵀ[i]\n",
    "h₄₄ᵀ= [sparse([1],[N^2+2*N+i],T(1),1,M) for i=1:N] # h₄₄⁽ⁱ⁾ᵀ=h₄₄ᵀ[i]\n",
    "const q₄ = -γ*p_bar # q₄⁽ⁱ⁾=q₄⁽ⁱ⁾[i]\n",
    "\n",
    "# chance constraints\n",
    "# Prob(h₅ᵀ[i]z>=q₅[i])=delta[i]\n",
    "h₅ᵀmat = hcat(spzeros(T,N,N^2),spzeros(T,N,N),sparse(I,N,N),spzeros(T,N,N))\n",
    "const h₅ᵀ= [h₅ᵀmat[i, :] for i in 1:N]\n",
    "const q₅ = w\n",
    "\n",
    "# objective function\n",
    "# max or min E[h₀ᵀz]\n",
    "h₀₃ᵀ= transpose(Ex)\n",
    "h₀₄ᵀ=-ones(T,1,N)\n",
    "const h₀ᵀ = hcat(spzeros(T,1,N^2),spzeros(T,1,N),h₀₃ᵀ,h₀₄ᵀ)\n",
    "\n",
    "# spy(H₀)\n",
    "# spy(H₀[1:N^2,1:N^2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9167bc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @show (typeof(low),typeof(upp))\n",
    "# @show (typeof(hᵀ),typeof(q))\n",
    "# @show (typeof(H))\n",
    "# @show (typeof(h₄₄ᵀ[1]),typeof(H₄[1]),typeof(h₄ᵀ[1]),typeof(q₄[1]))\n",
    "# @show (typeof(h₅ᵀ[1]),typeof(q₅[1]))\n",
    "# @show (typeof(h₀ᵀ))\n",
    "\n",
    "# objective function\n",
    "# max or min E[h₀ᵀz]\n",
    "#s.t.\n",
    "# upper and lower bounds\n",
    "# low<=z<=upp\n",
    "# linear constraints\n",
    "# hᵀz=q\n",
    "# quadratic constraints\n",
    "# zᵀHz = 0\n",
    "# nonlinear constraints\n",
    "# [h₄₄ᵀ[i]z=min{p_bar[i],max{zᵀH₄[i]z+h₄ᵀ[i]z+q₄[i],0}} for i=1,2,...,N]\n",
    "# note: h₄ᵀ[i] depends on x\n",
    "# chance constraints\n",
    "# Prob(h₅ᵀ[i]z>=q₅[i])=delta[i]\n",
    "\n",
    "\n",
    "# spy(H₀)\n",
    "# spy(H₀[1:N^2,1:N^2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b293dd2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×18 Matrix{Float32}:\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  -1.0  -1.0  -1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const lowA=Array(low)\n",
    "const uppA=Array(upp)\n",
    "const hᵀA=Array(hᵀ)\n",
    "const qA=Array(q)\n",
    "const HA=Array(H)\n",
    "const h₄₄ᵀA=Array(h₄₄ᵀ)\n",
    "const H₄A=Array(H₄)\n",
    "const h₄ᵀA=Array(h₄ᵀ)\n",
    "const q₄A=Array(q₄)\n",
    "const h₅ᵀA=Array(h₅ᵀ)\n",
    "const q₅A=Array(q₅)\n",
    "const h₀ᵀA=Array(h₀ᵀ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "573fab9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using Convex, SCS, ProxSDP, CSDP, Tulip\n",
    "# z = Variable(M,Positive()) # z=[vec(A),b,c,p]\n",
    "# problem = maximize(h₀ᵀ*z)\n",
    "# problem.constraints = [\n",
    "#                         z>=low,z<=upp,\n",
    "#                         hᵀ*z==q,\n",
    "#                         transpose(z)*H*z == 0,\n",
    "#                         [h₄₄ᵀ[i]*z==transpose(z)*H₄[i]*z+h₄ᵀ[i]*z+q₄[i] for i=1:N]...,\n",
    "#                        ]\n",
    "#Convex.solve!(problem,  SCS.Optimizer(verbose=true, eps=1e-10,linear_solver=SCS.DirectSolver), warmstart=false)\n",
    "#Convex.solve!(problem,  ProxSDP.Optimizer())\n",
    "# Convex.solve!(problem,  CSDP.Optimizer())\n",
    "# Convex.solve!(problem,  Tulip.Optimizer())\n",
    "# @show problem.status \n",
    "# @show  problem.optval\n",
    "\n",
    "\n",
    "# upper and lower bounds\n",
    "# low<=z<=upp\n",
    "# hᵀz=q\n",
    "# zᵀHz = 0\n",
    "# nonlinear constraints\n",
    "# [h₄₄ᵀ[i]z=min{p_bar[i],max{zᵀH₄[i]z+h₄ᵀ[i]z+q₄[i],0}} for i=1,2,...,N]\n",
    "# note: h₄ᵀ[i] depends on x\n",
    "\n",
    "# chance constraints\n",
    "# Prob(h₅ᵀ[i]z>=q₅[i])=delta[i]\n",
    "\n",
    "# objective function\n",
    "# max or min E[h₀ᵀz]\n",
    "\n",
    "# zsol=evaluate(z)\n",
    "# Asol = reshape(zsol[1:N^2],N,N)\n",
    "# bsol=zsol[N^2+1:N^2+N]\n",
    "# csol=zsol[N^2+N+1:N^2+2*N]\n",
    "# psol=zsol[N^2+2*N+1:N^2+3*N]\n",
    "\n",
    "# display(Asol)\n",
    "# display(bsol)\n",
    "# display(csol)\n",
    "# display(psol)\n",
    "# data.p_bar\n",
    "\n",
    "# tol = 1e-5\n",
    "# @testset \"check solution\" begin\n",
    "#     @test norm( sum(Asol,dims=2).* data.p_bar .- (data.p_bar .- bsol)) < tol\n",
    "#     @test norm( Asol' * data.p_bar .- (data.assets .- csol)) < tol\n",
    "#     @test all(-tol .<= Asol .<=1+tol)\n",
    "#     @test all(-tol .<= bsol .<=data.p_bar .+tol)\n",
    "#     @test all(-tol .<= csol .<=data.assets .+tol)   \n",
    "#     @test all(-tol .<= psol .<=data.p_bar .+tol) \n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45b80e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial guess\n",
    "rng =  Random.seed!(123)\n",
    "A0 = rand(N,N)#zeros(N,N)\n",
    "p0 = p_bar\n",
    "c0 = data_nm.c[1:N] \n",
    "b0 = data_nm.b[1:N]\n",
    "\n",
    "R = 3 # number of iid beta random variables\n",
    "α0 = 1.0*ones(R)\n",
    "β0= []\n",
    "for i=1:R\n",
    "    function ff!(F, x)\n",
    "        F[1] = 1-cdf(Beta(α0[i],x[1]),w[i]/c0[i])-delta[i] \n",
    "    end\n",
    "    if i==1\n",
    "        sol = nlsolve(ff!,[50.0])\n",
    "    else\n",
    "        sol = nlsolve(ff!,[1.0])\n",
    "    end\n",
    "    @test converged(sol)\n",
    "    push!(β0,sol.zero[1])\n",
    "end\n",
    "\n",
    "z0=vcat(A0...,b0,c0,p0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96401195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-5.444798678936011"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_pdf(x,p) = exp(DistributionsAD.logpdf(DistributionsAD.Beta(p[1],p[2]),x[1]))\n",
    "#Plots.plot([x->dist_pdf(x,[α0[i],β0[i]]) for i=1:N],0,1)\n",
    "\n",
    "function dist_cdf(p...)\n",
    "    α,β,wc = p[1], p[2], p[3]\n",
    "    s(x,wc) = 1 ./(1 .+exp.(-1000*(x-wc))) # approximates indicator function of x>=wc\n",
    "    obj(x,p) = dist_pdf(x,p)*s(x,wc...)\n",
    "    prob = QuadratureProblem(obj,0.0,1.0,[α...,β...])\n",
    "    Quadrature.solve(prob,QuadGKJL(),reltol=1e-5,abstol=1e-5)[1]\n",
    "end\n",
    "\n",
    "function dist_pdf_mv(x,params)\n",
    "           # α,β,A,b,c = params[1][1:N], params[1][N+1:2*N], params[1][2*N+1:2*N+N^2], params[1][2*N+N^2+1:3*N+N^2], params[1][3*N+N^2+1:4*N+N^2]\n",
    "            A,b,c,pp,α,β = params[1:N^2], params[N^2+1:N^2+N], params[N^2+N+1:N^2+2*N],  params[N^2+2*N+1:N^2+3*N], params[N^2+3*N+1:N^2+4*N], params[N^2+4*N+1:N^2+5*N]\n",
    "            A = reshape([A...],N,N) \n",
    "            joint_pdf = 1.0;\n",
    "            for i=1:N\n",
    "               joint_pdf = joint_pdf*dist_pdf(x[i],[α[i],β[i]]) \n",
    "            end\n",
    "\n",
    "            function contraction(x,p)\n",
    "               min.(p_bar, max.((1 .+γ).*(A'*p .+ c .- x.*c) .- γ.*p_bar,0))\n",
    "            end\n",
    "            contraction_iter(x, n::Integer) = n <= 0 ? p_bar  : contraction(x,contraction_iter(x,n-1))\n",
    "            loss_x(x) = -sum(contraction_iter(x,2))\n",
    "            loss_x(x)*joint_pdf\n",
    "end\n",
    "\n",
    "function ev(params...)\n",
    "    prob = QuadratureProblem(dist_pdf_mv,zeros(N),ones(N),[params...])\n",
    "    Quadrature.solve(prob,CubaCuhre(),reltol=1e-5,abstol=1e-5)[1]\n",
    "end\n",
    "\n",
    "ic = [z0...,α0...,β0...]\n",
    "dist_pdf_mv(ones(N)/10.0,ic)\n",
    "ev(ic...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2ce20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#m = Model(optimizer_with_attributes(EAGO.Optimizer))\n",
    "\n",
    "# alpine = optimizer_with_attributes(Alpine.Optimizer)\n",
    "# m = Model(alpine)\n",
    "\n",
    "# optimizer = Juniper.Optimizer\n",
    "# nl_solver = optimizer_with_attributes(Ipopt.Optimizer, \"print_level\"=>0)\n",
    "# m = Model(optimizer_with_attributes(optimizer, \"nl_solver\"=>nl_solver))\n",
    "\n",
    "# EAGO.Optimizer Ipopt.Optimizer EAGO, Alpine, Juniper, NLopt, Pavito\n",
    "\n",
    "# model = Model(NLopt.Optimizer)\n",
    "# set_optimizer_attribute(model, \"algorithm\", :LD_MMA)\n",
    "\n",
    "# solver = optimizer_with_attributes(\n",
    "#         Pavito.Optimizer,\n",
    "#         \"timeout\" => 120.0,\n",
    "#         \"mip_solver_drives\" => Ipopt,\n",
    "#         \"mip_solver\" => Ipopt,\n",
    "#         \"cont_solver\" => Ipopt\n",
    "#     )\n",
    "#  m = Model(solver)\n",
    "\n",
    "#m= Model(optimizer_with_attributes( SCIP.Optimizer))\n",
    "\n",
    "# objective function\n",
    "# max or min E[h₀ᵀz]\n",
    "#s.t.\n",
    "# upper and lower bounds\n",
    "# low<=z<=upp\n",
    "# linear constraints\n",
    "# hᵀz=q\n",
    "# quadratic constraints\n",
    "# zᵀHz = 0\n",
    "# nonlinear constraints\n",
    "# [h₄₄ᵀ[i]z=min{p_bar[i],max{zᵀH₄[i]z+h₄ᵀ[i]z+q₄[i],0}} for i=1,2,...,N]\n",
    "# note: h₄ᵀ[i] depends on x\n",
    "# chance constraints\n",
    "# Prob(h₅ᵀ[i]z>=q₅[i])=delta[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be26fded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "******************************************************************************\n",
      "This program contains Ipopt, a library for large-scale nonlinear optimization.\n",
      " Ipopt is released as open source code under the Eclipse Public License (EPL).\n",
      "         For more information visit https://github.com/coin-or/Ipopt\n",
      "******************************************************************************\n",
      "\n",
      "This is Ipopt version 3.13.4, running with linear solver mumps.\n",
      "NOTE: Other linear solvers might be more efficient (see Ipopt documentation).\n",
      "\n",
      "Number of nonzeros in equality constraint Jacobian...:       39\n",
      "Number of nonzeros in inequality constraint Jacobian.:        0\n",
      "Number of nonzeros in Lagrangian Hessian.............:        0\n",
      "\n",
      "Total number of variables............................:       21\n",
      "                     variables with only lower bounds:        0\n",
      "                variables with lower and upper bounds:       21\n",
      "                     variables with only upper bounds:        0\n",
      "Total number of equality constraints.................:       10\n",
      "Total number of inequality constraints...............:        0\n",
      "        inequality constraints with only lower bounds:        0\n",
      "   inequality constraints with lower and upper bounds:        0\n",
      "        inequality constraints with only upper bounds:        0\n",
      "\n",
      "iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n",
      "   0 -5.4447987e+00 3.61e+00 5.83e-10   0.0 0.00e+00    -  0.00e+00 0.00e+00   0\n",
      "   1 -5.4447987e+00 2.17e+00 4.77e+00   0.2 1.50e+00    -  1.00e+00 4.01e-01f  1\n",
      "   2 -5.4447986e+00 8.06e-01 5.18e+00  -0.2 2.93e+00    -  6.47e-01 6.28e-01h  1\n",
      "   3 -5.4401290e+00 1.16e-01 2.01e+00  -0.6 1.20e+00    -  1.00e+00 1.00e+00h  1\n",
      "   4 -5.4405232e+00 6.72e-02 5.68e+00  -0.6 5.36e-01    -  6.25e-01 1.00e+00h  1\n",
      "   5 -5.4403486e+00 5.73e-02 4.31e+00  -0.3 4.05e-01    -  7.99e-01 3.21e-01h  1\n",
      "   6 -5.4406540e+00 3.96e-02 1.33e+01  -0.4 1.72e-01    -  7.87e-01 7.52e-01h  1\n",
      "   7 -5.4406087e+00 9.74e-03 1.20e+01  -1.0 1.08e-01    -  1.00e+00 7.59e-01h  1\n",
      "   8 -5.4405536e+00 4.21e-03 9.41e+00  -1.4 1.18e-01    -  1.00e+00 5.97e-01h  1\n",
      "   9 -5.4405878e+00 2.04e-03 6.24e+00  -2.2 5.34e-02    -  1.00e+00 7.48e-01h  1\n",
      "iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n",
      "  10 -5.4405891e+00 1.48e-03 3.33e+01  -3.7 1.73e-02    -  1.00e+00 2.75e-01h  1\n",
      "  11 -5.4406010e+00 1.10e-03 1.52e+02  -5.1 5.94e-02    -  1.00e+00 2.79e-01h  1\n",
      "  12 -5.4406533e+00 2.76e-04 4.41e+00  -6.2 5.01e-02    -  1.00e+00 1.00e+00h  1\n",
      "  13 -5.4406751e+00 6.91e-05 1.10e+00  -6.9 2.33e-02    -  1.00e+00 1.00e+00h  1\n",
      "  14 -5.4406877e+00 1.73e-05 3.17e-01  -7.5 1.19e-02    -  1.00e+00 1.00e+00h  1\n",
      "  15 -5.4406940e+00 4.34e-06 8.04e-02  -8.1 5.98e-03    -  1.00e+00 1.00e+00h  1\n",
      "  16 -5.4406972e+00 1.10e-06 2.15e-02  -8.7 3.07e-03    -  1.00e+00 1.00e+00h  1\n",
      "  17 -5.4406988e+00 2.85e-07 3.09e-03  -9.3 1.54e-03    -  1.00e+00 1.00e+00h  1\n",
      "  18 -5.4406999e+00 1.40e-07 1.30e-03  -7.5 1.12e-03    -  1.00e+00 1.00e+00h  1\n",
      "  19 -5.4407000e+00 1.35e-07 4.36e-05  -8.0 4.73e-03    -  1.00e+00 7.58e-02h  1\n",
      "iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n",
      "  20 -5.4407001e+00 1.13e-07 1.18e-04  -9.1 1.00e+00    -  1.00e+00 1.98e-01h  1\n",
      "  21 -5.4406999e+00 3.86e-08 2.70e-05  -9.9 1.94e-01    -  1.00e+00 1.00e+00h  1\n",
      "  22 -5.4407080e+00 3.18e-07 4.14e-05 -11.0 3.54e-01    -  1.00e+00 1.00e+00h  1\n",
      "  23 -5.4407431e+00 4.22e-06 8.68e-04 -11.0 2.08e+00    -  1.00e+00 1.00e+00h  1\n",
      "  24 -5.4408571e+00 3.08e-05 4.27e-04 -11.0 5.84e+00    -  1.00e+00 1.00e+00h  1\n",
      "The Jacobian for the equality constraints contains an invalid number\n",
      "\n",
      "Number of Iterations....: 25\n",
      "\n",
      "Number of objective function evaluations             = 26\n",
      "Number of objective gradient evaluations             = 26\n",
      "Number of equality constraint evaluations            = 26\n",
      "Number of inequality constraint evaluations          = 0\n",
      "Number of equality constraint Jacobian evaluations   = 26\n",
      "Number of inequality constraint Jacobian evaluations = 0\n",
      "Number of Lagrangian Hessian evaluations             = 0\n",
      "Total CPU secs in IPOPT (w/o function evaluations)   =     58.048\n",
      "Total CPU secs in NLP function evaluations           =   2383.592\n",
      "\n",
      "EXIT: Invalid number in NLP function or derivative detected.\n"
     ]
    }
   ],
   "source": [
    "m = Model(optimizer_with_attributes(Ipopt.Optimizer,\"max_iter\"=>100000,\"print_level\"=>5))\n",
    "\n",
    "@variable(m, lowA[i]<=z[i=1:M]<=uppA[i],start=z0[i]) \n",
    "@variable(m, 1.0<=α[i=1:N]<=1.1, start = α0[i]) \n",
    "@variable(m, 1.0<=β[i=1:N]<=150.0, start = β0[i]) \n",
    "\n",
    "@constraint(m, hᵀA*z.==qA) \n",
    "@constraint(m,transpose(z)*HA*z==0) \n",
    "\n",
    "# match probabilities of default\n",
    "JuMP.register(m, :dist_cdf, 3, dist_cdf, autodiff=true)\n",
    "@NLexpression(m,wc[i=1:N],w[i]/z[N^2+N+i]) #c[i] = z[N^2+N+i]\n",
    "for i in 1:N\n",
    "    @eval ($(Symbol(\"vv$i\"))) = [α[$i],β[$i],wc[$i]]\n",
    "    @eval @NLconstraint(m,dist_cdf(($(Symbol(\"vv$i\")))...)== delta[$i]) \n",
    "end\n",
    "\n",
    "#[fix(c[i], data.c[i]; force=true) for i  in nm_c] #fixing c to data\n",
    "#[fix(b[i], data.b[i]; force=true) for i  in nm_b] #fixing b to data\n",
    "[fix(α[i], 1.0; force=true) for i=1:N] #fixing b to data\n",
    "\n",
    "#JuMP.register(m, :ev, M+N, ev, autodiff=true)\n",
    "JuMP.register(m, :ev, 5*N+N^2, ev, autodiff=true)\n",
    "vars = [z...,α...,β...]\n",
    "@NLobjective(m, Min, ev(vars...)  )\n",
    "\n",
    "unset_silent(m)\n",
    "JuMP.optimize!(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfc3a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "st = termination_status(m)\n",
    "objSol = objective_value(m)\n",
    "\n",
    "zsol = JuMP.value.(z);\n",
    "Asol = reshape(zsol[1:N^2],N,N)\n",
    "bsol = zsol[N^2+1:N^2+N] \n",
    "p_bar\n",
    "csol = zsol[N^2+N+1:N^2+2*N]\n",
    "\n",
    "αsol = α0\n",
    "βsol = JuMP.value.(β)\n",
    "\n",
    "#ev_pdf(x,p) = x*dist_pdf(x,p)\n",
    "#prob = QuadratureProblem(ev_pdf,0.0,1.0,[α0[1],β0[1]])\n",
    "#Ex = Quadrature.solve(prob,QuadGKJL(),reltol=1e-5,abstol=1e-5)[1] # CubaCuhre(),QuadGKJL()\n",
    "Ex = αsol[1]/(αsol[1]+βsol[1])\n",
    "trueObj= objSol + sum(Ex.*csol) + sum(p_bar)\n",
    "@show st, objSol, trueObj\n",
    "\n",
    "cdf_pkg = [1-cdf(Beta(αsol[i],βsol[i]),w[i]/csol[i]) for i=1:R]\n",
    "#cdf_opt = [dist_cdf([αsol[i],βsol[i],w[i]/csol[i] ]...) for i=1:R]\n",
    "tol = 1e-5\n",
    "@testset \"check solution\" begin\n",
    "    @test norm( sum(Asol,dims=2).* data.p_bar .- (data.p_bar .- bsol)) < tol\n",
    "    @test norm( Asol' * data.p_bar .- (data.assets .- csol)) < tol\n",
    "    @test norm(diag(Asol)) < tol\n",
    "    @test norm([Asol[i,j]*Asol[j,i] for i=1:N , j=1:N]) < tol\n",
    "    @test all(-tol .<=Asol.<=1+tol)\n",
    "    @test all(-tol .<=bsol.<=data.p_bar .+ tol)\n",
    "    @test all(-tol .<=csol.<=data.assets .+ tol)   \n",
    "\n",
    "   # @test norm(cdf_pkg-cdf_opt)<0.01\n",
    "    @test norm(delta-cdf_pkg)<0.001\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e127c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b5eba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@show L_opt = sum(p_bar)+objSol+sum(Ex.*csol)\n",
    "#sum(Ex.*csol)+max.(0,x.-w)\n",
    "\n",
    "xw=0.0\n",
    "for i=1:R\n",
    "    prob = QuadratureProblem((x,p)->max.(0,x-w[i])*dist_pdf(x,[αsol[i],βsol[i]]) ,0.0,1.0,[])\n",
    "    xw += Quadrature.solve(prob,QuadGKJL(),reltol=1e-5,abstol=1e-3)[1] # CubaCuhre(),QuadGKJL()\n",
    "end\n",
    "\n",
    "L_d=sum(Ex.*csol)+xw\n",
    "β = (p_bar.-bsol)./p_bar # financial connectivity: proportion of liabilities inside the network\n",
    "β⁺ = maximum(β)\n",
    "\n",
    "@show (L_opt,L_d)\n",
    "ratio = L_opt/L_d\n",
    "bound = 1 + sum(delta.*csol)/((1-β⁺)*sum(csol))\n",
    "@show (ratio,bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad21d1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "objSol "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5ab435",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687494b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pkg.add(\"JuMP\")\n",
    "# Pkg.add(\"Ipopt\")\n",
    "# Pkg.add(\"Distributions\")\n",
    "# Pkg.add(\"DistributionsAD\")\n",
    "# Pkg.add(\"SpecialFunctions\")\n",
    "# Pkg.add(\"NLsolve\")\n",
    "# Pkg.add(\"Quadrature\")\n",
    "# Pkg.add(\"Cubature\")\n",
    "# Pkg.add(\"QuadGK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fb3b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial guess\n",
    "g0 = γ\n",
    "rng =  Random.seed!(123)\n",
    "A0 = zeros(N,N)\n",
    "c0 = data_nm.c \n",
    "b0 = data_nm.b\n",
    "α0 = 1.0*ones(N)\n",
    "β0= []\n",
    "for i=1:N\n",
    "    function ff!(F, x)\n",
    "        F[1] = 1-cdf(Beta(α0[i],x[1]),w[i]/c0[i])-delta[i] \n",
    "    end\n",
    "    if i==1\n",
    "        sol = nlsolve(ff!,[50.0])\n",
    "    else\n",
    "        sol = nlsolve(ff!,[1.0])\n",
    "    end\n",
    "    @test converged(sol)\n",
    "    push!(β0,sol.zero[1])\n",
    "end\n",
    "\n",
    "dist_pdf(x,p) = exp(DistributionsAD.logpdf(DistributionsAD.Beta(p[1],p[2]),x[1]))\n",
    "#Plots.plot([x->dist_pdf(x,[α0[i],β0[i]]) for i=1:N],0,1)\n",
    "\n",
    "function dist_cdf(p...)\n",
    "    α,β,wc = p[1], p[2], p[3]\n",
    "    s(x,wc) = 1 ./(1 .+exp.(-1000*(x-wc))) # approximates indicator function of x>=wc\n",
    "    obj(x,p) = dist_pdf(x,p)*s(x,wc...)\n",
    "    prob = QuadratureProblem(obj,0.0,1.0,[α...,β...])\n",
    "    Quadrature.solve(prob,QuadGKJL(),reltol=1e-5,abstol=1e-5)[1]\n",
    "end\n",
    "\n",
    "function dist_pdf_mv(x,params)\n",
    "           # α,β,A,b,c = params[1][1:N], params[1][N+1:2*N], params[1][2*N+1:2*N+N^2], params[1][2*N+N^2+1:3*N+N^2], params[1][3*N+N^2+1:4*N+N^2]\n",
    "            α,β,A,b,c = params[1:N], params[N+1:2*N], params[2*N+1:2*N+N^2], params[2*N+N^2+1:3*N+N^2], params[3*N+N^2+1:4*N+N^2]\n",
    "            A = reshape([A...],N,N) \n",
    "            joint_pdf = 1.0;\n",
    "            for i=1:N\n",
    "               joint_pdf = joint_pdf*dist_pdf(x[i],[α[i],β[i]]) \n",
    "            end\n",
    "\n",
    "            function contraction(x,p)\n",
    "               min.(p_bar, max.((1 .+g0).*(A'*p .+ c .- x.*c) .- g0.*p_bar,0))\n",
    "            end\n",
    "            contraction_iter(x, n::Integer) = n <= 0 ? p_bar  : contraction(x,contraction_iter(x,n-1))\n",
    "            loss_x(x) = -sum(contraction_iter(x,2)).*dist_pdf(x,[α...,β...])   \n",
    "            loss_x(x)*joint_pdf\n",
    "end\n",
    "\n",
    "\n",
    "# function dist_pdf_mv_test(x,params...)\n",
    "#     α,β,A,b,c = params[1:N], params[N+1:2*N], params[2*N+1:2*N+N^2], params[2*N+N^2+1:3*N+N^2], params[3*N+N^2+1:4*N+N^2]\n",
    "#     A = reshape([A...],N,N) \n",
    "#     joint_pdf=1.0;\n",
    "#     for i=1:N\n",
    "#         joint_pdf = joint_pdf*dist_pdf(x[i],[α[i],β[i]]) \n",
    "#     end\n",
    "#     #joint_pdf = prod(dist_pdf.(x,[α,β]))\n",
    "#     some_fun = x->sum(x) # some arbitrary function to test\n",
    "#     some_fun([α...,β...,A...,b...,c...])*joint_pdf \n",
    "# end\n",
    "# dist_pdf_mv_test(ones(N)/12.0,ic...)\n",
    "\n",
    "function ev(params...)\n",
    "    prob = QuadratureProblem(dist_pdf_mv,zeros(N),ones(N),[params...])\n",
    "    Quadrature.solve(prob,CubaCuhre(),reltol=1e-5,abstol=1e-5)[1]\n",
    "end\n",
    "\n",
    "z0 = [A0...,b0...,c0...,p0...]\n",
    "dist_pdf_mv(ones(N)/10.0,ic)\n",
    "ev(z0...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ee2dca",
   "metadata": {},
   "outputs": [],
   "source": [
    " A1,b1,c1 = z0[1:N^2], z0[N^2+1:N^2+N], z0[N^2+N+1:N^2+2*N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d66f333",
   "metadata": {},
   "outputs": [],
   "source": [
    "reshape(A1,N,N)==A0\n",
    "b1==b0\n",
    "c1==c0\n",
    "N^2+2*N\n",
    "M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d46640c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up optimization\n",
    "# m = Model(with_optimizer(Ipopt.Optimizer, start_with_resto=\"yes\", linear_solver=\"mumps\",max_iter=10000,hessian_approximation=\"limited-memory\"))\n",
    "m = Model(optimizer_with_attributes(Ipopt.Optimizer,\"max_iter\"=>100000,\"print_level\"=>5))\n",
    "\n",
    "@variable(m, low[i]<=z[i=1:N]<=upp[i], start = z0[i]) \n",
    "@constraint(m, hᵀ*z==q) \n",
    "\n",
    "JuMP.register(m, :ev, 4*N+N^2, ev, autodiff=true)\n",
    "@NLobjective(m, Max , ev(z...)  )\n",
    "\n",
    "unset_silent(m)\n",
    "@time JuMP.optimize!(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b8984b",
   "metadata": {},
   "outputs": [],
   "source": [
    "st0 = termination_status(m)\n",
    "obj0 = objective_value(m)\n",
    "@show st0, obj0\n",
    "\n",
    "csol0 = JuMP.value.(c)\n",
    "bsol0 = JuMP.value.(b)\n",
    "Asol0 = JuMP.value.(A)\n",
    "αsol0 = JuMP.value.(α)\n",
    "βsol0 = JuMP.value.(β)\n",
    "\n",
    "cdf_pkg = [1-cdf(Beta(αsol0[i],βsol0[i]),w[i]/csol0[i]) for i=1:N]\n",
    "cdf_opt = [dist_cdf([αsol0[i],βsol0[i],w[i]/csol0[i] ]...) for i=1:N]\n",
    "tol = 1e-5\n",
    "@testset \"check solution\" begin\n",
    "    @test norm( sum(Asol0,dims=2).* data.p_bar .- (data.p_bar .- bsol0)) < tol\n",
    "    @test norm( Asol0' * data.p_bar .- (data.assets .- csol0)) < tol\n",
    "    @test norm(diag(Asol0)) < tol\n",
    "    @test norm([Asol0[i,j]*Asol0[j,i] for i=1:N , j=1:N]) < tol\n",
    "    @test all(0 .<=Asol0.<=1)\n",
    "    @test all(0 .<=bsol0.<=data.p_bar)\n",
    "    @test all(0 .<=csol0.<=data.assets)   \n",
    "\n",
    "    @test norm(cdf_pkg-cdf_opt)<0.01\n",
    "    @test norm(delta-cdf_opt)<0.01\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce6769b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import Pkg;Pkg.add(\"CUDA\")\n",
    "using CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5f018e",
   "metadata": {},
   "outputs": [],
   "source": [
    "using CUDA\n",
    "\n",
    "@show attribute(device(),CUDA.DEVICE_ATTRIBUTE_MAX_GRID_DIM_X)\n",
    "@show attribute(device(),CUDA.DEVICE_ATTRIBUTE_MAX_BLOCK_DIM_X)\n",
    "@show attribute(device(),CUDA.DEVICE_ATTRIBUTE_MAX_THREADS_PER_BLOCK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba107b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "function print_index()\n",
    "    CUDA.@cuprint blockIdx().x\n",
    "    return\n",
    "end\n",
    "\n",
    "@cuda threads=4 print_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd94fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "using CUDA, Test\n",
    "@test has_cuda_gpu()\n",
    "\n",
    "# the GPU has a grid composed of a number of blocks\n",
    "# each block has a number of threads\n",
    "\n",
    "# grids and blocks can be one, two, or three-dimensional\n",
    "# e.g., we can have a grid with 30 blocks in the x direction and no blocks in the other two directions, i.e., blocks = 30 \n",
    "# or we can have a grid with 2 blocks in the x direction, 3 in the y direction and 5 in the z-direction, i.e., blocks = (2,3,5)\n",
    "# the number of blocks is the same but they are indexed differently\n",
    "# same logic applies for threads inside blocks\n",
    "\n",
    "# size limits\n",
    "# requesting grids or blocks that are too large and violate these limits will result in an error\n",
    "\n",
    "# check maximum number of blocks for the grid \n",
    "@show attribute(device(),CUDA.DEVICE_ATTRIBUTE_MAX_GRID_DIM_X)\n",
    "@show attribute(device(),CUDA.DEVICE_ATTRIBUTE_MAX_GRID_DIM_Y)\n",
    "@show attribute(device(),CUDA.DEVICE_ATTRIBUTE_MAX_GRID_DIM_Z)\n",
    "\n",
    "# check maximum total number of threads per block\n",
    "@show attribute(device(),CUDA.DEVICE_ATTRIBUTE_MAX_THREADS_PER_BLOCK)\n",
    "\n",
    "# check maximum size of threads per block in each dimension\n",
    "@show attribute(device(),CUDA.DEVICE_ATTRIBUTE_MAX_BLOCK_DIM_X)\n",
    "@show attribute(device(),CUDA.DEVICE_ATTRIBUTE_MAX_BLOCK_DIM_Y)\n",
    "@show attribute(device(),CUDA.DEVICE_ATTRIBUTE_MAX_BLOCK_DIM_Z)\n",
    "\n",
    "# CUDA provides nice print functions that allow you to check what each thread/block is doing\n",
    "function par_thread(m)\n",
    "    id = threadIdx().x\n",
    "    CUDA.@cuprint m[id]\n",
    "    CUDA.@cuprintf(\"Thread %ld printed m[%ld]=%lf\\n\",id,id,m[id])\n",
    "    return\n",
    "end\n",
    "\n",
    "# parallelize over threads \n",
    "mat_gpu = CUDA.rand(3,5)\n",
    "\n",
    "function par_thread(m)\n",
    "    id = threadIdx().x\n",
    "    CUDA.@cuprintf(\"Printed by thread %ld outside the if \\n\",id)\n",
    "    if (id <= length(m))\n",
    "        CUDA.@cuprintf(\"Thread %ld processed m[%ld]=%lf\\n\",id,id,m[id])\n",
    "    end\n",
    "    return\n",
    "end\n",
    "\n",
    "# compare the output of these three cases:\n",
    "@cuda threads=2 par_thread(mat_gpu)\n",
    "@cuda threads=length(mat_gpu) par_thread(mat_gpu)\n",
    "@cuda threads=2*length(mat_gpu) par_thread(mat_gpu)\n",
    "\n",
    "# parallelize over threads and blocks\n",
    "function par_thread_blocks(m)\n",
    "    tid = threadIdx().x # thread index inside a block\n",
    "    bid = blockIdx().x # block index\n",
    "    gid = (tid - 1) + (bid - 1) * blockDim().x # global index of all threads inside all blocks (the minus one is to index starting at zero)\n",
    "    CUDA.@cuprintf(\"Printed by thread %ld in block %ld, with global index %ld \\n\",tid,bid,gid)\n",
    "    return\n",
    "end\n",
    "# compare the output of these two cases:\n",
    "@cuda threads=2 par_thread_blocks(mat_gpu)\n",
    "@cuda threads=2 blocks=3 par_thread_blocks(mat_gpu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb374dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297f080f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.0",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
